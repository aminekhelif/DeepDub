{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-1.57.4-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from openai) (4.6.2.post1)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from openai) (0.27.2)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from openai) (2.10.1)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Using cached openai-1.57.4-py3-none-any.whl (390 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.8.2-cp39-cp39-macosx_11_0_arm64.whl (300 kB)\n",
      "Installing collected packages: jiter, distro, openai\n",
      "Successfully installed distro-1.9.0 jiter-0.8.2 openai-1.57.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:1234/v1\",\n",
    "    api_key = 'lms'\n",
    ")\n",
    "\n",
    "class PreprocessingAgent:\n",
    "    def __init__(self):\n",
    "        self.units_regex = r\"\\d+\\s*(miles|kilometers|pounds|kilograms)\"\n",
    "\n",
    "    def identify_critical_segments(self, dialogue):\n",
    "        # Rule-based unit detection\n",
    "        critical_entities = []\n",
    "        if re.search(self.units_regex, dialogue):\n",
    "            critical_entities.append(\"Unit Conversion\")\n",
    "\n",
    "        # OpenAI-based detection of expressions\n",
    "        expressions = self.detect_expressions(dialogue)\n",
    "        if expressions:\n",
    "            critical_entities.extend([f\"Expression: {expr}\" for expr in expressions])\n",
    "\n",
    "        # OpenAI-based cultural reference detection\n",
    "        cultural_reference = self.detect_cultural_reference(dialogue)\n",
    "        if cultural_reference:\n",
    "            critical_entities.append(f\"Cultural Reference: {cultural_reference}\")\n",
    "\n",
    "        if critical_entities:\n",
    "            return f\"Detected Critical Entities: {', '.join(critical_entities)}\"\n",
    "\n",
    "        return \"Standard\"\n",
    "\n",
    "    def detect_cultural_reference(self, dialogue):\n",
    "        # LLM-based detection with OpenAI GPT model\n",
    "        prompt = f\"Analyze the following text and identify if it contains any cultural references or expressions. If so, explain:\\n\\n\\\"{dialogue}\\\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in detecting cultural references in text.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    def detect_expressions(self, dialogue):\n",
    "        # Use OpenAI GPT model to detect expressions dynamically\n",
    "        prompt = f\"Analyze the following text and list all idiomatic expressions or common phrases:\\n\\n\\\"{dialogue}\\\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in identifying idiomatic expressions.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        expressions = response.choices[0].message.content.strip()\n",
    "        return [expr.strip() for expr in expressions.split(',') if expr.strip()]\n",
    "\n",
    "class TranslationAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def translate(self, dialogue):\n",
    "        # Use OpenAI GPT model for translation\n",
    "        prompt = f\"Translate the following English text into French:\\n\\n\\\"{dialogue}\\\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert translator from English to French.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "class ContextualAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def adapt_context(self, dialogue):\n",
    "        # Use OpenAI GPT model for contextual adaptation\n",
    "        prompt = f\"Refine the following French translation to better fit the context:\\n\\n\\\"{dialogue}\\\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in refining translations for better contextual accuracy.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "class ManualValidationAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def validate(self, original, contextual):\n",
    "        print(\"Original:\", original)\n",
    "        print(\"Contextual Translation:\", contextual)\n",
    "        user_input = input(\"Enter your validation or press Enter to accept: \")\n",
    "        return user_input if user_input.strip() else contextual\n",
    "\n",
    "class OptimizationAgent:\n",
    "    def __init__(self, max_chars=42):\n",
    "        self.max_chars = max_chars\n",
    "\n",
    "    def optimize(self, dialogue):\n",
    "        if len(dialogue) > self.max_chars:\n",
    "            return dialogue[:self.max_chars-3] + \"...\"\n",
    "        return dialogue\n",
    "\n",
    "class DialogueTranslationPipeline:\n",
    "    def __init__(self):\n",
    "        self.preprocessing_agent = PreprocessingAgent()\n",
    "        self.translation_agent = TranslationAgent()\n",
    "        self.contextual_agent = ContextualAgent()\n",
    "        self.manual_validation_agent = ManualValidationAgent()\n",
    "        self.optimization_agent = OptimizationAgent()\n",
    "\n",
    "    def process_dialogue(self, dialogue):\n",
    "        # Step 1: Preprocessing\n",
    "        critical_type = self.preprocessing_agent.identify_critical_segments(dialogue)\n",
    "        print(f\"Critical Segment Type: {critical_type}\")\n",
    "\n",
    "        # Step 2: Translation\n",
    "        translated = self.translation_agent.translate(dialogue)\n",
    "        print(f\"Translated: {translated}\")\n",
    "\n",
    "        # Step 3: Contextual Adaptation\n",
    "        contextual = self.contextual_agent.adapt_context(translated)\n",
    "        print(f\"Contextual Translation: {contextual}\")\n",
    "\n",
    "        # Step 4: Manual Validation\n",
    "        validated = self.manual_validation_agent.validate(dialogue, contextual)\n",
    "\n",
    "        # Step 5: Optimization\n",
    "        optimized = self.optimization_agent.optimize(validated)\n",
    "        print(f\"Final Optimized Translation: {optimized}\")\n",
    "\n",
    "        return optimized\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical Segment Type: Detected Critical Entities: Expression: In the provided text, Expression: there are two idiomatic expressions:\n",
      "\n",
      "1. **\"A piece of cake\"**: This idiom means that something is very easy to accomplish.\n",
      "\n",
      "2. **\"Break the ice\"**: This expression refers to doing or saying something to relieve tension or get a conversation started in a social setting.\n",
      "\n",
      "These phrases are commonly used to convey ease and the initiation of interaction, Expression: respectively., Cultural Reference: The text you provided does contain cultural references and expressions that are commonly used in English-speaking contexts.\n",
      "\n",
      "1. **\"The meeting was a piece of cake\":** This is an idiomatic expression meaning that something was very easy to accomplish or required little effort. The phrase \"piece of cake\" originates from the notion that eating cake is enjoyable and simple, thus likening an easy task to this experience. It reflects a cultural tendency in English to use food-related metaphors for ease and simplicity.\n",
      "\n",
      "2. **\"He's gonna break the ice\":** This is another idiomatic expression meaning that someone will initiate conversation or activity to create a more relaxed atmosphere among people who may be feeling awkward, reserved, or unfamiliar with one another. The origin of this phrase likely comes from the idea of breaking through literal ice to clear a path for navigation or communication, metaphorically applying it to social interactions.\n",
      "\n",
      "Both expressions are widely recognized in English-speaking cultures and are used frequently in both formal and informal contexts.\n",
      "Translated: La réunion s'est déroulée sans problème et il va briser la glace.\n",
      "Contextual Translation: To refine this translation and ensure it fits the context more accurately, we should consider what \"break the ice\" typically means in English. It often refers to initiating conversation or easing tension among people who might be unfamiliar with each other. In a professional setting, like a meeting, it could mean starting the formal proceedings or making an initial announcement.\n",
      "\n",
      "Here's a refined translation:\n",
      "\n",
      "\"La réunion s'est déroulée sans problème et il va maintenant démarrer les discussions.\"\n",
      "\n",
      "This version suggests that after the trouble-free start of the meeting, he will begin to engage participants in conversation or discussion. This captures the idea of \"breaking the ice\" more contextually within a meeting setting.\n",
      "Original: The meeting was a piece of cake, and he's gonna break the ice.\n",
      "Contextual Translation: To refine this translation and ensure it fits the context more accurately, we should consider what \"break the ice\" typically means in English. It often refers to initiating conversation or easing tension among people who might be unfamiliar with each other. In a professional setting, like a meeting, it could mean starting the formal proceedings or making an initial announcement.\n",
      "\n",
      "Here's a refined translation:\n",
      "\n",
      "\"La réunion s'est déroulée sans problème et il va maintenant démarrer les discussions.\"\n",
      "\n",
      "This version suggests that after the trouble-free start of the meeting, he will begin to engage participants in conversation or discussion. This captures the idea of \"breaking the ice\" more contextually within a meeting setting.\n",
      "Final Optimized Translation: To refine this translation and ensure i...\n",
      "Result: To refine this translation and ensure i...\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "pipeline = DialogueTranslationPipeline()\n",
    "dialogue = \"The meeting was a piece of cake, and he's gonna break the ice.\"\n",
    "result = pipeline.process_dialogue(dialogue)\n",
    "print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, Any, List\n",
    "from openai import OpenAI\n",
    "\n",
    "# ======================\n",
    "# Agents & Functions\n",
    "# ======================\n",
    "\n",
    "class TerminologyAgent:\n",
    "    def __init__(self, initial_glossary: Dict[str, str] = None):\n",
    "        self.glossary = initial_glossary if initial_glossary else {}\n",
    "\n",
    "    def apply_glossary(self, text: str) -> str:\n",
    "        for term, trans in self.glossary.items():\n",
    "            text = text.replace(term, trans)\n",
    "        return text\n",
    "\n",
    "\n",
    "class DomainExpertAgent:\n",
    "    def __init__(self, domain_knowledge: Dict[str, str] = None):\n",
    "        self.domain_knowledge = domain_knowledge if domain_knowledge else {}\n",
    "\n",
    "    def refine_translation(self, text: str) -> str:\n",
    "        for term, trans in self.domain_knowledge.items():\n",
    "            text = text.replace(term, trans)\n",
    "        return text\n",
    "\n",
    "\n",
    "class TranslatorAgent:\n",
    "    def __init__(self, target_lang: str = \"en\", terminology_agent: TerminologyAgent = None, domain_agent: DomainExpertAgent = None, client=None):\n",
    "        self.target_lang = target_lang\n",
    "        self.terminology_agent = terminology_agent\n",
    "        self.domain_agent = domain_agent\n",
    "        self.client = client\n",
    "\n",
    "    def translate_text(self, source_text: str) -> str:\n",
    "        prompt = f\"Translate this text into {self.target_lang}: {source_text}\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are an expert translator into {self.target_lang}.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        translated = response.choices[0].message.content.strip()\n",
    "\n",
    "        if self.terminology_agent:\n",
    "            translated = self.terminology_agent.apply_glossary(translated)\n",
    "        if self.domain_agent:\n",
    "            translated = self.domain_agent.refine_translation(translated)\n",
    "\n",
    "        return translated\n",
    "\n",
    "\n",
    "class StylisticEditorAgent:\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "\n",
    "    def improve_style(self, text_segments: List[str]) -> List[str]:\n",
    "        improved_segments = []\n",
    "        for segment in text_segments:\n",
    "            prompt = (f\"Improve the style and fluency of the following translated segment without changing its meaning:\\n\\nSegment: {segment}\")\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a professional stylistic editor.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.0\n",
    "            )\n",
    "            improved = response.choices[0].message.content.strip()\n",
    "            improved_segments.append(improved)\n",
    "        return improved_segments\n",
    "\n",
    "\n",
    "class QualityCheckerAgent:\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "\n",
    "    def check_quality(self, text_segments: List[str]) -> bool:\n",
    "        segment_list_str = \"\\n\".join([f\"Segment {i+1}: {seg}\" for i, seg in enumerate(text_segments)])\n",
    "        prompt = (\n",
    "            \"You are an expert in translation quality assessment. The following are translated segments. \"\n",
    "            \"Evaluate each segment from 1 to 10 for its overall quality (accuracy, style, fluency). \"\n",
    "            \"Then respond in strict JSON with the schema:\\n\"\n",
    "            \"{\\n\"\n",
    "            \"  \\\"ratings\\\": [\\n\"\n",
    "            \"    {\\n\"\n",
    "            \"      \\\"segment\\\": <segment_number>,\\n\"\n",
    "            \"      \\\"rating\\\": <integer_rating>,\\n\"\n",
    "            \"      \\\"comment\\\": \\\"justification\\\"\\n\"\n",
    "            \"    }\\n\"\n",
    "            \"  ],\\n\"\n",
    "            \"  \\\"all_above_seven\\\": <true_or_false>\\n\"\n",
    "            \"}\\n\\n\"\n",
    "            f\"{segment_list_str}\"\n",
    "        )\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional bilingual translator and reviewer.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        result_str = response.choices[0].message.content.strip()\n",
    "        try:\n",
    "            result_json = json.loads(result_str)\n",
    "            return bool(result_json.get(\"all_above_seven\", True))\n",
    "        except json.JSONDecodeError:\n",
    "            return True\n",
    "\n",
    "    def suggest_fixes(self, text_segments: List[str]) -> List[str]:\n",
    "        segment_list_str = \"\\n\".join([f\"Segment {i+1}: {seg}\" for i, seg in enumerate(text_segments)])\n",
    "        prompt = (\n",
    "            \"These segments need improvement. Please propose improved versions that maintain meaning but enhance accuracy and fluency.\\n\\n\"\n",
    "            f\"{segment_list_str}\\n\\n\"\n",
    "            \"Reply in JSON as:\\n\"\n",
    "            \"{\\n\"\n",
    "            \"  \\\"improved_segments\\\": [\\n\"\n",
    "            \"    {\\\"segment\\\": <segment_number>, \\\"improved_text\\\": \\\"...\\\"}\\n\"\n",
    "            \"  ]\\n\"\n",
    "            \"}\"\n",
    "        )\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional translator and editor.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        result_str = response.choices[0].message.content.strip()\n",
    "        try:\n",
    "            result_json = json.loads(result_str)\n",
    "            improved_segments = []\n",
    "            for entry in result_json.get(\"improved_segments\", []):\n",
    "                improved_segments.append(entry[\"improved_text\"])\n",
    "            return improved_segments\n",
    "        except json.JSONDecodeError:\n",
    "            return text_segments\n",
    "\n",
    "\n",
    "class GlobalCoordinatorAgent:\n",
    "    def __init__(self, translators: List[TranslatorAgent], \n",
    "                 editor: StylisticEditorAgent, \n",
    "                 quality_checker: QualityCheckerAgent):\n",
    "        self.translators = translators\n",
    "        self.editor = editor\n",
    "        self.quality_checker = quality_checker\n",
    "\n",
    "    def process_segments(self, segments: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        # Traduction\n",
    "        results = []\n",
    "        for i, seg in enumerate(segments):\n",
    "            translator = self.translators[i % len(self.translators)]\n",
    "            translated_text = translator.translate_text(seg[\"text\"])\n",
    "            results.append({\n",
    "                \"speaker_id\": seg[\"speaker_id\"],\n",
    "                \"start\": seg[\"start\"],\n",
    "                \"end\": seg[\"end\"],\n",
    "                \"translated_text\": translated_text\n",
    "            })\n",
    "\n",
    "        # Edition stylistique\n",
    "        all_translations = [r[\"translated_text\"] for r in results]\n",
    "        improved = self.editor.improve_style(all_translations)\n",
    "        for i, r in enumerate(results):\n",
    "            r[\"translated_text\"] = improved[i]\n",
    "\n",
    "        # Vérification Qualité\n",
    "        if not self.quality_checker.check_quality([r[\"translated_text\"] for r in results]):\n",
    "            fixed = self.quality_checker.suggest_fixes([r[\"translated_text\"] for r in results])\n",
    "            for i, r in enumerate(results):\n",
    "                r[\"translated_text\"] = fixed[i]\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "def extract_terminology_and_domain_knowledge(client: OpenAI, source_text: str, target_language: str = \"en\") -> (Dict[str, str], Dict[str, str]):\n",
    "    function_definition = {\n",
    "        \"name\": \"extract_domain_and_glossary\",\n",
    "        \"description\": \"Extract domain-specific terms and initial glossary terms from text, returning structured dictionaries.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"domain_knowledge\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"description\": \"Key-value pairs of domain-specific terms mapped to their explanations or translations\",\n",
    "                    \"additionalProperties\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"initial_glossary\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"description\": \"Key-value pairs of terms mapped to their target equivalents\",\n",
    "                    \"additionalProperties\": {\"type\": \"string\"}\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"domain_knowledge\", \"initial_glossary\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a terminology extraction assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "Analyze the following text and identify:\n",
    "1. Domain-specific terms (technical jargon, specialized components) relevant to the domain. For each domain-specific term, provide a short explanation or a translation into {target_language}.\n",
    "2. An initial glossary of key terms (proper nouns, repetitive keywords) and their target equivalents in {target_language}.\n",
    "\n",
    "Return your answer by calling the function `extract_domain_and_glossary` with a JSON structure:\n",
    "{{\n",
    "  \"domain_knowledge\": {{ \"term_in_source\": \"explanation_or_translation_in_{target_language}\" }},\n",
    "  \"initial_glossary\": {{ \"term_in_source\": \"equivalent_in_{target_language}\" }}\n",
    "}}\n",
    "\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": \"Voici un extrait technique d'aéronautique:\\n\\nDans ce manuel technique d'aéronautique, nous allons étudier la maintenance du turbopropulseur XJ-200. Le XJ-200 est un moteur à hélice couplé à une turbine à gaz spécialement conçu pour les avions de ligne régionaux. Il nécessite un ajustement précis du pas d'hélice, un contrôle régulier des injecteurs de carburant, et une calibration du compresseur. L'entreprise ACME AeroParts fournit également des pièces détachées spécifiques, comme les filtres à particules fines et les senseurs de température PT100.\"}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "        functions=[function_definition],\n",
    "        function_call={\"name\": \"extract_domain_and_glossary\"},\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "    arguments_str = response.choices[0].message.function_call.arguments\n",
    "    parsed = json.loads(arguments_str)\n",
    "\n",
    "    domain_knowledge = parsed[\"domain_knowledge\"]\n",
    "    initial_glossary = parsed[\"initial_glossary\"]\n",
    "\n",
    "    return domain_knowledge, initial_glossary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# Utilisation de la pipeline\n",
    "# ======================\n",
    "\n",
    "\n",
    "\n",
    "# Initialisation du client OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:1234/v1\",\n",
    "    api_key='lms'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Exemple d'input JSON de segments\n",
    "input_json = \"\"\"\n",
    "[\n",
    "    {\"speaker_id\": \"S1\", \"start\":0.0, \"end\":2.5, \"text\":\"Bonjour, comment l'examen s'est derouler ?\"},\n",
    "    {\"speaker_id\": \"S2\", \"start\":2.5, \"end\":5.0, \"text\":\"l'examen etait un jeu d'enfant\"},\n",
    "    {\"speaker_id\": \"S1\", \"start\":5.0, \"end\":7.0, \"text\":\"super, content de l'entendre\"}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "segments = json.loads(input_json)\n",
    "\n",
    "\n",
    "# Extraction automatique du glossaire et de la terminologie (par exemple en anglais)\n",
    "target_language = \"en\"\n",
    "domain_knowledge, initial_glossary = extract_terminology_and_domain_knowledge(client, \"Texte source ci-dessus\", target_language)\n",
    "\n",
    "domain_agent = DomainExpertAgent(domain_knowledge=domain_knowledge)\n",
    "terminology_agent = TerminologyAgent(initial_glossary=initial_glossary)\n",
    "\n",
    "translator_1 = TranslatorAgent(target_lang=target_language, terminology_agent=terminology_agent, domain_agent=domain_agent, client=client)\n",
    "translator_2 = TranslatorAgent(target_lang=target_language, terminology_agent=terminology_agent, domain_agent=domain_agent, client=client)\n",
    "\n",
    "stylistic_editor = StylisticEditorAgent(client=client)\n",
    "quality_checker = QualityCheckerAgent(client=client)\n",
    "\n",
    "coordinator = GlobalCoordinatorAgent(translators=[translator_1, translator_2],\n",
    "                                     editor=stylistic_editor, \n",
    "                                     quality_checker=quality_checker)\n",
    "\n",
    "final_results = coordinator.process_segments(segments)\n",
    "\n",
    "# Définition de la fonction pour la sortie structurée\n",
    "function_definition_output = {\n",
    "    \"name\": \"generate_output\",\n",
    "    \"description\": \"Generate structured output with cultural references, wordplay, idiomatic expressions, acronyms, measurement units, and final translated segments.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"cultural_references\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\"},\n",
    "                \"description\": \"List of detected cultural references.\"\n",
    "            },\n",
    "            \"wordplay\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\"},\n",
    "                \"description\": \"List of instances of wordplay.\"\n",
    "            },\n",
    "            \"idiomatic_expressions\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\"},\n",
    "                \"description\": \"List of idiomatic expressions.\"\n",
    "            },\n",
    "            \"acronyms\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\"},\n",
    "                \"description\": \"List of acronyms.\"\n",
    "            },\n",
    "            \"measurement_units\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\"},\n",
    "                \"description\": \"List of measurement units.\"\n",
    "            },\n",
    "            \"translated_segments\": {\n",
    "                \"type\": \"array\",\n",
    "                \"description\": \"The translated segments.\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"speaker_id\": {\"type\": \"string\"},\n",
    "                        \"start\": {\"type\": \"number\"},\n",
    "                        \"end\": {\"type\": \"number\"},\n",
    "                        \"translated_text\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"required\": [\"speaker_id\", \"start\", \"end\", \"translated_text\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"translated_segments\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "final_prompt = (\n",
    "    \"Analyze the following translated segments and extract:\\n\"\n",
    "    \"- Cultural references\\n\"\n",
    "    \"- Wordplay\\n\"\n",
    "    \"- Idiomatic expressions\\n\"\n",
    "    \"- Acronyms\\n\"\n",
    "    \"- Measurement units\\n\\n\"\n",
    "    \"Then return a JSON structure with these fields plus the translated segments.\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that returns data in a structured format.\"},\n",
    "    {\"role\": \"user\", \"content\": final_prompt},\n",
    "    {\"role\": \"user\", \"content\": json.dumps(final_results, ensure_ascii=False)}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=messages,\n",
    "    functions=[function_definition_output],\n",
    "    function_call={\"name\": \"generate_output\"},\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "structured_output = response.choices[0].message.function_call.arguments\n",
    "parsed_output = json.loads(structured_output)\n",
    "\n",
    "# Affichage final\n",
    "print(json.dumps(parsed_output, indent=4, ensure_ascii=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepDub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
