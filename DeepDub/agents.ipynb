{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-1.57.4-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from openai) (4.6.2.post1)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from openai) (0.27.2)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from openai) (2.10.1)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/envs/DeepDub/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Using cached openai-1.57.4-py3-none-any.whl (390 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.8.2-cp39-cp39-macosx_11_0_arm64.whl (300 kB)\n",
      "Installing collected packages: jiter, distro, openai\n",
      "Successfully installed distro-1.9.0 jiter-0.8.2 openai-1.57.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:1234/v1\",\n",
    "    api_key = 'lms'\n",
    ")\n",
    "\n",
    "class PreprocessingAgent:\n",
    "    def __init__(self):\n",
    "        self.units_regex = r\"\\d+\\s*(miles|kilometers|pounds|kilograms)\"\n",
    "\n",
    "    def identify_critical_segments(self, dialogue):\n",
    "        # Rule-based unit detection\n",
    "        critical_entities = []\n",
    "        if re.search(self.units_regex, dialogue):\n",
    "            critical_entities.append(\"Unit Conversion\")\n",
    "\n",
    "        # OpenAI-based detection of expressions\n",
    "        expressions = self.detect_expressions(dialogue)\n",
    "        if expressions:\n",
    "            critical_entities.extend([f\"Expression: {expr}\" for expr in expressions])\n",
    "\n",
    "        # OpenAI-based cultural reference detection\n",
    "        cultural_reference = self.detect_cultural_reference(dialogue)\n",
    "        if cultural_reference:\n",
    "            critical_entities.append(f\"Cultural Reference: {cultural_reference}\")\n",
    "\n",
    "        if critical_entities:\n",
    "            return f\"Detected Critical Entities: {', '.join(critical_entities)}\"\n",
    "\n",
    "        return \"Standard\"\n",
    "\n",
    "    def detect_cultural_reference(self, dialogue):\n",
    "        # LLM-based detection with OpenAI GPT model\n",
    "        prompt = f\"Analyze the following text and identify if it contains any cultural references or expressions. If so, explain:\\n\\n\\\"{dialogue}\\\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in detecting cultural references in text.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "    def detect_expressions(self, dialogue):\n",
    "        # Use OpenAI GPT model to detect expressions dynamically\n",
    "        prompt = f\"Analyze the following text and list all idiomatic expressions or common phrases:\\n\\n\\\"{dialogue}\\\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in identifying idiomatic expressions.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        expressions = response.choices[0].message.content.strip()\n",
    "        return [expr.strip() for expr in expressions.split(',') if expr.strip()]\n",
    "\n",
    "class TranslationAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def translate(self, dialogue):\n",
    "        # Use OpenAI GPT model for translation\n",
    "        prompt = f\"Translate the following English text into French:\\n\\n\\\"{dialogue}\\\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert translator from English to French.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "class ContextualAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def adapt_context(self, dialogue):\n",
    "        # Use OpenAI GPT model for contextual adaptation\n",
    "        prompt = f\"Refine the following French translation to better fit the context:\\n\\n\\\"{dialogue}\\\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in refining translations for better contextual accuracy.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "class ManualValidationAgent:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def validate(self, original, contextual):\n",
    "        print(\"Original:\", original)\n",
    "        print(\"Contextual Translation:\", contextual)\n",
    "        user_input = input(\"Enter your validation or press Enter to accept: \")\n",
    "        return user_input if user_input.strip() else contextual\n",
    "\n",
    "class OptimizationAgent:\n",
    "    def __init__(self, max_chars=42):\n",
    "        self.max_chars = max_chars\n",
    "\n",
    "    def optimize(self, dialogue):\n",
    "        if len(dialogue) > self.max_chars:\n",
    "            return dialogue[:self.max_chars-3] + \"...\"\n",
    "        return dialogue\n",
    "\n",
    "class DialogueTranslationPipeline:\n",
    "    def __init__(self):\n",
    "        self.preprocessing_agent = PreprocessingAgent()\n",
    "        self.translation_agent = TranslationAgent()\n",
    "        self.contextual_agent = ContextualAgent()\n",
    "        self.manual_validation_agent = ManualValidationAgent()\n",
    "        self.optimization_agent = OptimizationAgent()\n",
    "\n",
    "    def process_dialogue(self, dialogue):\n",
    "        # Step 1: Preprocessing\n",
    "        critical_type = self.preprocessing_agent.identify_critical_segments(dialogue)\n",
    "        print(f\"Critical Segment Type: {critical_type}\")\n",
    "\n",
    "        # Step 2: Translation\n",
    "        translated = self.translation_agent.translate(dialogue)\n",
    "        print(f\"Translated: {translated}\")\n",
    "\n",
    "        # Step 3: Contextual Adaptation\n",
    "        contextual = self.contextual_agent.adapt_context(translated)\n",
    "        print(f\"Contextual Translation: {contextual}\")\n",
    "\n",
    "        # Step 4: Manual Validation\n",
    "        validated = self.manual_validation_agent.validate(dialogue, contextual)\n",
    "\n",
    "        # Step 5: Optimization\n",
    "        optimized = self.optimization_agent.optimize(validated)\n",
    "        print(f\"Final Optimized Translation: {optimized}\")\n",
    "\n",
    "        return optimized\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical Segment Type: Detected Critical Entities: Expression: In the provided text, Expression: there are two idiomatic expressions:\n",
      "\n",
      "1. **\"A piece of cake\"**: This idiom means that something is very easy to accomplish.\n",
      "\n",
      "2. **\"Break the ice\"**: This expression refers to doing or saying something to relieve tension or get a conversation started in a social setting.\n",
      "\n",
      "These phrases are commonly used to convey ease and the initiation of interaction, Expression: respectively., Cultural Reference: The text you provided does contain cultural references and expressions that are commonly used in English-speaking contexts.\n",
      "\n",
      "1. **\"The meeting was a piece of cake\":** This is an idiomatic expression meaning that something was very easy to accomplish or required little effort. The phrase \"piece of cake\" originates from the notion that eating cake is enjoyable and simple, thus likening an easy task to this experience. It reflects a cultural tendency in English to use food-related metaphors for ease and simplicity.\n",
      "\n",
      "2. **\"He's gonna break the ice\":** This is another idiomatic expression meaning that someone will initiate conversation or activity to create a more relaxed atmosphere among people who may be feeling awkward, reserved, or unfamiliar with one another. The origin of this phrase likely comes from the idea of breaking through literal ice to clear a path for navigation or communication, metaphorically applying it to social interactions.\n",
      "\n",
      "Both expressions are widely recognized in English-speaking cultures and are used frequently in both formal and informal contexts.\n",
      "Translated: La réunion s'est déroulée sans problème et il va briser la glace.\n",
      "Contextual Translation: To refine this translation and ensure it fits the context more accurately, we should consider what \"break the ice\" typically means in English. It often refers to initiating conversation or easing tension among people who might be unfamiliar with each other. In a professional setting, like a meeting, it could mean starting the formal proceedings or making an initial announcement.\n",
      "\n",
      "Here's a refined translation:\n",
      "\n",
      "\"La réunion s'est déroulée sans problème et il va maintenant démarrer les discussions.\"\n",
      "\n",
      "This version suggests that after the trouble-free start of the meeting, he will begin to engage participants in conversation or discussion. This captures the idea of \"breaking the ice\" more contextually within a meeting setting.\n",
      "Original: The meeting was a piece of cake, and he's gonna break the ice.\n",
      "Contextual Translation: To refine this translation and ensure it fits the context more accurately, we should consider what \"break the ice\" typically means in English. It often refers to initiating conversation or easing tension among people who might be unfamiliar with each other. In a professional setting, like a meeting, it could mean starting the formal proceedings or making an initial announcement.\n",
      "\n",
      "Here's a refined translation:\n",
      "\n",
      "\"La réunion s'est déroulée sans problème et il va maintenant démarrer les discussions.\"\n",
      "\n",
      "This version suggests that after the trouble-free start of the meeting, he will begin to engage participants in conversation or discussion. This captures the idea of \"breaking the ice\" more contextually within a meeting setting.\n",
      "Final Optimized Translation: To refine this translation and ensure i...\n",
      "Result: To refine this translation and ensure i...\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "pipeline = DialogueTranslationPipeline()\n",
    "dialogue = \"The meeting was a piece of cake, and he's gonna break the ice.\"\n",
    "result = pipeline.process_dialogue(dialogue)\n",
    "print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, Any, List\n",
    "from openai import OpenAI\n",
    "\n",
    "# ======================\n",
    "# Agents & Functions\n",
    "# ======================\n",
    "\n",
    "class TerminologyAgent:\n",
    "    def __init__(self, initial_glossary: Dict[str, str] = None):\n",
    "        self.glossary = initial_glossary if initial_glossary else {}\n",
    "\n",
    "    def apply_glossary(self, text: str) -> str:\n",
    "        for term, trans in self.glossary.items():\n",
    "            text = text.replace(term, trans)\n",
    "        return text\n",
    "\n",
    "\n",
    "class DomainExpertAgent:\n",
    "    def __init__(self, domain_knowledge: Dict[str, str] = None):\n",
    "        self.domain_knowledge = domain_knowledge if domain_knowledge else {}\n",
    "\n",
    "    def refine_translation(self, text: str) -> str:\n",
    "        for term, trans in self.domain_knowledge.items():\n",
    "            text = text.replace(term, trans)\n",
    "        return text\n",
    "\n",
    "\n",
    "class TranslatorAgent:\n",
    "    def __init__(self, target_lang: str = \"en\", terminology_agent: TerminologyAgent = None, domain_agent: DomainExpertAgent = None, client=None):\n",
    "        self.target_lang = target_lang\n",
    "        self.terminology_agent = terminology_agent\n",
    "        self.domain_agent = domain_agent\n",
    "        self.client = client\n",
    "\n",
    "    def translate_text(self, source_text: str) -> str:\n",
    "        prompt = f\"Translate this text into {self.target_lang}: {source_text}\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are an expert translator into {self.target_lang}.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        translated = response.choices[0].message.content.strip()\n",
    "\n",
    "        if self.terminology_agent:\n",
    "            translated = self.terminology_agent.apply_glossary(translated)\n",
    "        if self.domain_agent:\n",
    "            translated = self.domain_agent.refine_translation(translated)\n",
    "\n",
    "        return translated\n",
    "\n",
    "\n",
    "class StylisticEditorAgent:\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "\n",
    "    def improve_style(self, text_segments: List[str]) -> List[str]:\n",
    "        improved_segments = []\n",
    "        for segment in text_segments:\n",
    "            prompt = (f\"Improve the style and fluency of the following translated segment without changing its meaning:\\n\\nSegment: {segment}\")\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a professional stylistic editor.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.0\n",
    "            )\n",
    "            improved = response.choices[0].message.content.strip()\n",
    "            improved_segments.append(improved)\n",
    "        return improved_segments\n",
    "\n",
    "\n",
    "class QualityCheckerAgent:\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "\n",
    "    def check_quality(self, text_segments: List[str]) -> bool:\n",
    "        segment_list_str = \"\\n\".join([f\"Segment {i+1}: {seg}\" for i, seg in enumerate(text_segments)])\n",
    "        prompt = (\n",
    "            \"You are an expert in translation quality assessment. The following are translated segments. \"\n",
    "            \"Evaluate each segment from 1 to 10 for its overall quality (accuracy, style, fluency). \"\n",
    "            \"Then respond in strict JSON with the schema:\\n\"\n",
    "            \"{\\n\"\n",
    "            \"  \\\"ratings\\\": [\\n\"\n",
    "            \"    {\\n\"\n",
    "            \"      \\\"segment\\\": <segment_number>,\\n\"\n",
    "            \"      \\\"rating\\\": <integer_rating>,\\n\"\n",
    "            \"      \\\"comment\\\": \\\"justification\\\"\\n\"\n",
    "            \"    }\\n\"\n",
    "            \"  ],\\n\"\n",
    "            \"  \\\"all_above_seven\\\": <true_or_false>\\n\"\n",
    "            \"}\\n\\n\"\n",
    "            f\"{segment_list_str}\"\n",
    "        )\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional bilingual translator and reviewer.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        result_str = response.choices[0].message.content.strip()\n",
    "        try:\n",
    "            result_json = json.loads(result_str)\n",
    "            return bool(result_json.get(\"all_above_seven\", True))\n",
    "        except json.JSONDecodeError:\n",
    "            return True\n",
    "\n",
    "    def suggest_fixes(self, text_segments: List[str]) -> List[str]:\n",
    "        segment_list_str = \"\\n\".join([f\"Segment {i+1}: {seg}\" for i, seg in enumerate(text_segments)])\n",
    "        prompt = (\n",
    "            \"These segments need improvement. Please propose improved versions that maintain meaning but enhance accuracy and fluency.\\n\\n\"\n",
    "            f\"{segment_list_str}\\n\\n\"\n",
    "            \"Reply in JSON as:\\n\"\n",
    "            \"{\\n\"\n",
    "            \"  \\\"improved_segments\\\": [\\n\"\n",
    "            \"    {\\\"segment\\\": <segment_number>, \\\"improved_text\\\": \\\"...\\\"}\\n\"\n",
    "            \"  ]\\n\"\n",
    "            \"}\"\n",
    "        )\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional translator and editor.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        result_str = response.choices[0].message.content.strip()\n",
    "        try:\n",
    "            result_json = json.loads(result_str)\n",
    "            improved_segments = []\n",
    "            for entry in result_json.get(\"improved_segments\", []):\n",
    "                improved_segments.append(entry[\"improved_text\"])\n",
    "            return improved_segments\n",
    "        except json.JSONDecodeError:\n",
    "            return text_segments\n",
    "\n",
    "\n",
    "class GlobalCoordinatorAgent:\n",
    "    def __init__(self, translators: List[TranslatorAgent], \n",
    "                 editor: StylisticEditorAgent, \n",
    "                 quality_checker: QualityCheckerAgent):\n",
    "        self.translators = translators\n",
    "        self.editor = editor\n",
    "        self.quality_checker = quality_checker\n",
    "\n",
    "    def process_segments(self, segments: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        # Traduction\n",
    "        results = []\n",
    "        for i, seg in enumerate(segments):\n",
    "            translator = self.translators[i % len(self.translators)]\n",
    "            translated_text = translator.translate_text(seg[\"text\"])\n",
    "            results.append({\n",
    "                \"speaker_id\": seg[\"speaker_id\"],\n",
    "                \"start\": seg[\"start\"],\n",
    "                \"end\": seg[\"end\"],\n",
    "                \"translated_text\": translated_text\n",
    "            })\n",
    "\n",
    "        # Edition stylistique\n",
    "        all_translations = [r[\"translated_text\"] for r in results]\n",
    "        improved = self.editor.improve_style(all_translations)\n",
    "        for i, r in enumerate(results):\n",
    "            r[\"translated_text\"] = improved[i]\n",
    "\n",
    "        # Vérification Qualité\n",
    "        if not self.quality_checker.check_quality([r[\"translated_text\"] for r in results]):\n",
    "            fixed = self.quality_checker.suggest_fixes([r[\"translated_text\"] for r in results])\n",
    "            for i, r in enumerate(results):\n",
    "                r[\"translated_text\"] = fixed[i]\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "def extract_terminology_and_domain_knowledge(client: OpenAI, source_text: str, target_language: str = \"en\") -> (Dict[str, str], Dict[str, str]):\n",
    "    function_definition = {\n",
    "        \"name\": \"extract_domain_and_glossary\",\n",
    "        \"description\": \"Extract domain-specific terms and initial glossary terms from text, returning structured dictionaries.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"domain_knowledge\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"description\": \"Key-value pairs of domain-specific terms mapped to their explanations or translations\",\n",
    "                    \"additionalProperties\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"initial_glossary\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"description\": \"Key-value pairs of terms mapped to their target equivalents\",\n",
    "                    \"additionalProperties\": {\"type\": \"string\"}\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"domain_knowledge\", \"initial_glossary\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a terminology extraction assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "Analyze the following text and identify:\n",
    "1. Domain-specific terms (technical jargon, specialized components) relevant to the domain. For each domain-specific term, provide a short explanation or a translation into {target_language}.\n",
    "2. An initial glossary of key terms (proper nouns, repetitive keywords) and their target equivalents in {target_language}.\n",
    "\n",
    "Return your answer by calling the function `extract_domain_and_glossary` with a JSON structure:\n",
    "{{\n",
    "  \"domain_knowledge\": {{ \"term_in_source\": \"explanation_or_translation_in_{target_language}\" }},\n",
    "  \"initial_glossary\": {{ \"term_in_source\": \"equivalent_in_{target_language}\" }}\n",
    "}}\n",
    "\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": \"Voici un extrait technique d'aéronautique:\\n\\nDans ce manuel technique d'aéronautique, nous allons étudier la maintenance du turbopropulseur XJ-200. Le XJ-200 est un moteur à hélice couplé à une turbine à gaz spécialement conçu pour les avions de ligne régionaux. Il nécessite un ajustement précis du pas d'hélice, un contrôle régulier des injecteurs de carburant, et une calibration du compresseur. L'entreprise ACME AeroParts fournit également des pièces détachées spécifiques, comme les filtres à particules fines et les senseurs de température PT100.\"}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "        functions=[function_definition],\n",
    "        function_call={\"name\": \"extract_domain_and_glossary\"},\n",
    "        temperature=0.0\n",
    "    )\n",
    "    print(response)\n",
    "    arguments_str = response.choices[0].message.function_call.arguments\n",
    "    parsed = json.loads(arguments_str)\n",
    "\n",
    "    domain_knowledge = parsed[\"domain_knowledge\"]\n",
    "    initial_glossary = parsed[\"initial_glossary\"]\n",
    "\n",
    "    return domain_knowledge, initial_glossary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-ybugmkiivwnq8hsijfryno', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='To analyze the given text and extract domain-specific terms and an initial glossary, I\\'ll first read through the text to understand its context and identify key terms.\\n\\nThe text is about a technical manual for maintaining the XJ-200 turboprop engine, which is used in regional airliners. It mentions specific maintenance tasks and components related to this type of aircraft engine.\\n\\n### Domain-Specific Terms\\n\\n1. **Turbopropulseur (Turboprop Engine)**: A turboprop engine is a type of aircraft engine that combines a turbine engine with a propeller. It\\'s efficient for medium-speed, medium-range flights.\\n\\n2. **Hélice (Propeller)**: A propeller is a device with blades that rotate to generate thrust, pulling or pushing an aircraft through the air.\\n\\n3. **Turbine à gaz (Gas Turbine)**: A gas turbine is a type of engine that operates by burning fuel in a continuous stream of air, producing hot gases that turn the turbine blades to generate power.\\n\\n4. **Ajustement précis du pas d\\'hélice (Precise Pitch Adjustment of the Propeller)**: The pitch of a propeller refers to the angle of its blades. Adjusting the pitch changes the amount of thrust produced and is crucial for engine performance and efficiency.\\n\\n5. **Injecteurs de carburant (Fuel Injectors)**: Fuel injectors are components that supply fuel to the engine in a precise manner, ensuring efficient combustion.\\n\\n6. **Calibration du compresseur (Compressor Calibration)**: The compressor is a part of the turbine that compresses air before it enters the combustion chamber. Calibrating the compressor ensures it operates efficiently and effectively.\\n\\n7. **Filtres à particules fines (Fine Particle Filters)**: These filters are designed to remove small particles from the air, preventing them from entering the engine and causing damage.\\n\\n8. **Senseurs de température PT100 (PT100 Temperature Sensors)**: PT100 sensors are resistance temperature detectors used to measure temperature in various parts of the engine, ensuring it operates within safe limits.\\n\\n### Initial Glossary\\n\\n1. **XJ-200**: Likely a specific model of turboprop engine. No direct translation needed; it\\'s a proper noun.\\n\\n2. **ACME AeroParts**: The name of a company that provides spare parts for aircraft engines. Again, a proper noun.\\n\\n3. **Pièces détachées spécifiques (Specific Spare Parts)**: Refers to particular components designed for the XJ-200 engine.\\n\\n4. **Filtres à particules fines (Fine Particle Filters)**: As explained above.\\n\\n5. **Senseurs de température PT100 (PT100 Temperature Sensors)**: As explained above.\\n\\n### Final JSON Structure\\n\\n```json\\n{\\n  \"domain_knowledge\": {\\n    \"turbopropulseur\": \"Turboprop Engine\",\\n    \"hélice\": \"Propeller\",\\n    \"turbine à gaz\": \"Gas Turbine\",\\n    \"ajustement précis du pas d\\'hélice\": \"Precise Pitch Adjustment of the Propeller\",\\n    \"injecteurs de carburant\": \"Fuel Injectors\",\\n    \"calibration du compresseur\": \"Compressor Calibration\",\\n    \"filtres à particules fines\": \"Fine Particle Filters\",\\n    \"senseurs de température PT100\": \"PT100 Temperature Sensors\"\\n  },\\n  \"initial_glossary\": {\\n    \"XJ-200\": \"XJ-200\",\\n    \"ACME AeroParts\": \"ACME AeroParts\",\\n    \"pièces détachées spécifiques\": \"Specific Spare Parts\",\\n    \"filtres à particules fines\": \"Fine Particle Filters\",\\n    \"senseurs de température PT100\": \"PT100 Temperature Sensors\"\\n  }\\n}\\n```\\n\\n### Explanation\\n\\n- **Domain-Specific Terms**: These are technical terms specific to aeronautical engineering and turboprop engine maintenance. Each term is translated or explained in English to provide clarity for someone not familiar with the domain.\\n\\n- **Initial Glossary**: This includes both proper nouns (like XJ-200 and ACME AeroParts) and repetitive keywords that are important for understanding the text. The glossary provides target equivalents in English where applicable.\\n\\nThis approach ensures that both the technical depth of the subject matter and the specific terminology used in the text are captured and explained appropriately.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1734423160, model='qwq-32b-preview@q4_k_m', object='chat.completion', service_tier=None, system_fingerprint='qwq-32b-preview@q4_k_m', usage=CompletionUsage(completion_tokens=935, prompt_tokens=306, total_tokens=1241, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'arguments'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Extraction automatique du glossaire et de la terminologie (par exemple en anglais)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m target_language \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m domain_knowledge, initial_glossary \u001b[38;5;241m=\u001b[39m \u001b[43mextract_terminology_and_domain_knowledge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTexte source ci-dessus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_language\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m domain_agent \u001b[38;5;241m=\u001b[39m DomainExpertAgent(domain_knowledge\u001b[38;5;241m=\u001b[39mdomain_knowledge)\n\u001b[1;32m     32\u001b[0m terminology_agent \u001b[38;5;241m=\u001b[39m TerminologyAgent(initial_glossary\u001b[38;5;241m=\u001b[39minitial_glossary)\n",
      "Cell \u001b[0;32mIn[12], line 229\u001b[0m, in \u001b[0;36mextract_terminology_and_domain_knowledge\u001b[0;34m(client, source_text, target_language)\u001b[0m\n\u001b[1;32m    221\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    222\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    227\u001b[0m )\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[0;32m--> 229\u001b[0m arguments_str \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_call\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marguments\u001b[49m\n\u001b[1;32m    230\u001b[0m parsed \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(arguments_str)\n\u001b[1;32m    232\u001b[0m domain_knowledge \u001b[38;5;241m=\u001b[39m parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdomain_knowledge\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'arguments'"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# Utilisation de la pipeline\n",
    "# ======================\n",
    "\n",
    "\n",
    "\n",
    "# Initialisation du client OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:1234/v1\",\n",
    "    api_key='lms'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Exemple d'input JSON de segments\n",
    "input_json = \"\"\"\n",
    "[\n",
    "    {\"speaker_id\": \"S1\", \"start\":0.0, \"end\":2.5, \"text\":\"Bonjour, comment l'examen s'est derouler ?\"},\n",
    "    {\"speaker_id\": \"S2\", \"start\":2.5, \"end\":5.0, \"text\":\"l'examen etait un jeu d'enfant\"},\n",
    "    {\"speaker_id\": \"S1\", \"start\":5.0, \"end\":7.0, \"text\":\"super, content de l'entendre\"}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "segments = json.loads(input_json)\n",
    "\n",
    "\n",
    "# Extraction automatique du glossaire et de la terminologie (par exemple en anglais)\n",
    "target_language = \"en\"\n",
    "domain_knowledge, initial_glossary = extract_terminology_and_domain_knowledge(client, \"Texte source ci-dessus\", target_language)\n",
    "\n",
    "domain_agent = DomainExpertAgent(domain_knowledge=domain_knowledge)\n",
    "terminology_agent = TerminologyAgent(initial_glossary=initial_glossary)\n",
    "\n",
    "translator_1 = TranslatorAgent(target_lang=target_language, terminology_agent=terminology_agent, domain_agent=domain_agent, client=client)\n",
    "translator_2 = TranslatorAgent(target_lang=target_language, terminology_agent=terminology_agent, domain_agent=domain_agent, client=client)\n",
    "\n",
    "stylistic_editor = StylisticEditorAgent(client=client)\n",
    "quality_checker = QualityCheckerAgent(client=client)\n",
    "\n",
    "coordinator = GlobalCoordinatorAgent(translators=[translator_1, translator_2],\n",
    "                                     editor=stylistic_editor, \n",
    "                                     quality_checker=quality_checker)\n",
    "\n",
    "final_results = coordinator.process_segments(segments)\n",
    "\n",
    "# Définition de la fonction pour la sortie structurée\n",
    "function_definition_output = {\n",
    "    \"name\": \"generate_output\",\n",
    "    \"description\": \"Generate structured output with cultural references, wordplay, idiomatic expressions, acronyms, measurement units, and final translated segments.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"cultural_references\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\"},\n",
    "                \"description\": \"List of detected cultural references.\"\n",
    "            },\n",
    "            \"wordplay\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\"},\n",
    "                \"description\": \"List of instances of wordplay.\"\n",
    "            },\n",
    "            \"idiomatic_expressions\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\"},\n",
    "                \"description\": \"List of idiomatic expressions.\"\n",
    "            },\n",
    "            \"acronyms\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\"},\n",
    "                \"description\": \"List of acronyms.\"\n",
    "            },\n",
    "            \"measurement_units\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\"},\n",
    "                \"description\": \"List of measurement units.\"\n",
    "            },\n",
    "            \"translated_segments\": {\n",
    "                \"type\": \"array\",\n",
    "                \"description\": \"The translated segments.\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"speaker_id\": {\"type\": \"string\"},\n",
    "                        \"start\": {\"type\": \"number\"},\n",
    "                        \"end\": {\"type\": \"number\"},\n",
    "                        \"translated_text\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"required\": [\"speaker_id\", \"start\", \"end\", \"translated_text\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"translated_segments\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "final_prompt = (\n",
    "    \"Analyze the following translated segments and extract:\\n\"\n",
    "    \"- Cultural references\\n\"\n",
    "    \"- Wordplay\\n\"\n",
    "    \"- Idiomatic expressions\\n\"\n",
    "    \"- Acronyms\\n\"\n",
    "    \"- Measurement units\\n\\n\"\n",
    "    \"Then return a JSON structure with these fields plus the translated segments.\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that returns data in a structured format.\"},\n",
    "    {\"role\": \"user\", \"content\": final_prompt},\n",
    "    {\"role\": \"user\", \"content\": json.dumps(final_results, ensure_ascii=False)}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=messages,\n",
    "    functions=[function_definition_output],\n",
    "    function_call={\"name\": \"generate_output\"},\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "structured_output = response.choices[0].message.function_call.arguments\n",
    "parsed_output = json.loads(structured_output)\n",
    "\n",
    "# Affichage final\n",
    "print(json.dumps(parsed_output, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class ExtractionResult(BaseModel):\n",
    "    \"\"\"Model for holding extraction results from domain and glossary extraction.\"\"\"\n",
    "    domain_knowledge: Dict[str, str] = Field(...)\n",
    "    initial_glossary: Dict[str, str] = Field(...)\n",
    "\n",
    "\n",
    "class SegmentInput(BaseModel):\n",
    "    \"\"\"Model representing input segments to be translated.\"\"\"\n",
    "    speaker_id: str\n",
    "    start: float\n",
    "    end: float\n",
    "    text: str\n",
    "\n",
    "\n",
    "class TranslatedSegment(BaseModel):\n",
    "    \"\"\"Model representing a translated segment.\"\"\"\n",
    "    speaker_id: str\n",
    "    start: float\n",
    "    end: float\n",
    "    translated_text: str\n",
    "\n",
    "\n",
    "class FinalOutput(BaseModel):\n",
    "    \"\"\"Final output model after analyzing translated segments.\"\"\"\n",
    "    cultural_references: List[str] = Field(default=[])\n",
    "    wordplay: List[str] = Field(default=[])\n",
    "    idiomatic_expressions: List[str] = Field(default=[])\n",
    "    acronyms: List[str] = Field(default=[])\n",
    "    measurement_units: List[str] = Field(default=[])\n",
    "    translated_segments: List[TranslatedSegment] = Field(...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List\n",
    "import json\n",
    "\n",
    "class TerminologyAgent:\n",
    "    \"\"\"Applies a given glossary to translated text.\"\"\"\n",
    "    def __init__(self, initial_glossary: Dict[str, str] = None):\n",
    "        self.glossary = initial_glossary if initial_glossary else {}\n",
    "\n",
    "    def apply_glossary(self, text: str) -> str:\n",
    "        for term, trans in self.glossary.items():\n",
    "            text = text.replace(term, trans)\n",
    "        return text\n",
    "\n",
    "\n",
    "class DomainExpertAgent:\n",
    "    \"\"\"Refines translation based on domain-specific knowledge.\"\"\"\n",
    "    def __init__(self, domain_knowledge: Dict[str, str] = None):\n",
    "        self.domain_knowledge = domain_knowledge if domain_knowledge else {}\n",
    "\n",
    "    def refine_translation(self, text: str) -> str:\n",
    "        for term, trans in self.domain_knowledge.items():\n",
    "            text = text.replace(term, trans)\n",
    "        return text\n",
    "\n",
    "\n",
    "class TranslatorAgent:\n",
    "    \"\"\"Translates text using the given client (OpenAI) and applies terminology/domain refinements.\"\"\"\n",
    "    def __init__(self, target_lang: str, terminology_agent: TerminologyAgent, domain_agent: DomainExpertAgent, client):\n",
    "        self.target_lang = target_lang\n",
    "        self.terminology_agent = terminology_agent\n",
    "        self.domain_agent = domain_agent\n",
    "        self.client = client\n",
    "\n",
    "    def translate_text(self, source_text: str) -> str:\n",
    "        prompt = f\"Translate this text into {self.target_lang}: {source_text}\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are an expert translator into {self.target_lang}.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        translated = response.choices[0].message.content.strip()\n",
    "        translated = self.terminology_agent.apply_glossary(translated)\n",
    "        translated = self.domain_agent.refine_translation(translated)\n",
    "        return translated\n",
    "\n",
    "\n",
    "class StylisticEditorAgent:\n",
    "    \"\"\"Improves style and fluency of translated segments.\"\"\"\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "\n",
    "    def improve_style(self, text_segments: List[str]) -> List[str]:\n",
    "        improved_segments = []\n",
    "        for segment in text_segments:\n",
    "            prompt = (f\"Improve the style and fluency of the following translated segment \"\n",
    "                      f\"without changing its meaning:\\n\\nSegment: {segment}\")\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a professional stylistic editor.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.0\n",
    "            )\n",
    "            improved = response.choices[0].message.content.strip()\n",
    "            improved_segments.append(improved)\n",
    "        return improved_segments\n",
    "\n",
    "\n",
    "class QualityCheckerAgent:\n",
    "    \"\"\"Checks the quality of the translated segments and suggests improvements if needed.\"\"\"\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "\n",
    "    def check_quality(self, text_segments: List[str]) -> bool:\n",
    "        segment_list_str = \"\\n\".join([f\"Segment {i+1}: {seg}\" for i, seg in enumerate(text_segments)])\n",
    "        prompt = (\n",
    "            \"You are an expert in translation quality assessment. The following are translated segments. \"\n",
    "            \"Evaluate each segment from 1 to 10 for its overall quality (accuracy, style, fluency). \"\n",
    "            \"Then respond in strict JSON with the schema:\\n\"\n",
    "            \"{\\n\"\n",
    "            \"  \\\"ratings\\\": [\\n\"\n",
    "            \"    {\\n\"\n",
    "            \"      \\\"segment\\\": <segment_number>,\\n\"\n",
    "            \"      \\\"rating\\\": <integer_rating>,\\n\"\n",
    "            \"      \\\"comment\\\": \\\"justification\\\"\\n\"\n",
    "            \"    }\\n\"\n",
    "            \"  ],\\n\"\n",
    "            \"  \\\"all_above_seven\\\": <true_or_false>\\n\"\n",
    "            \"}\\n\\n\"\n",
    "            f\"{segment_list_str}\"\n",
    "        )\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional bilingual translator and reviewer.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        result_str = response.choices[0].message.content.strip()\n",
    "        try:\n",
    "            result_json = json.loads(result_str)\n",
    "            return bool(result_json.get(\"all_above_seven\", True))\n",
    "        except json.JSONDecodeError:\n",
    "            # If parsing fails, assume quality is acceptable\n",
    "            return True\n",
    "\n",
    "    def suggest_fixes(self, text_segments: List[str]) -> List[str]:\n",
    "        segment_list_str = \"\\n\".join([f\"Segment {i+1}: {seg}\" for i, seg in enumerate(text_segments)])\n",
    "        prompt = (\n",
    "            \"These segments need improvement. Please propose improved versions that maintain meaning \"\n",
    "            \"but enhance accuracy and fluency.\\n\\n\"\n",
    "            f\"{segment_list_str}\\n\\n\"\n",
    "            \"Reply in JSON as:\\n\"\n",
    "            \"{\\n\"\n",
    "            \"  \\\"improved_segments\\\": [\\n\"\n",
    "            \"    {\\\"segment\\\": <segment_number>, \\\"improved_text\\\": \\\"...\\\"}\\n\"\n",
    "            \"  ]\\n\"\n",
    "            \"}\"\n",
    "        )\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional translator and editor.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        result_str = response.choices[0].message.content.strip()\n",
    "        try:\n",
    "            result_json = json.loads(result_str)\n",
    "            improved_segments = []\n",
    "            for entry in result_json.get(\"improved_segments\", []):\n",
    "                improved_segments.append(entry[\"improved_text\"])\n",
    "            return improved_segments\n",
    "        except json.JSONDecodeError:\n",
    "            # If parsing fails, return original segments\n",
    "            return text_segments\n",
    "\n",
    "\n",
    "class GlobalCoordinatorAgent:\n",
    "    \"\"\"Coordinates translation, editing, and quality checking of segments.\"\"\"\n",
    "    def __init__(self, translators: List[TranslatorAgent], \n",
    "                 editor: StylisticEditorAgent, \n",
    "                 quality_checker: QualityCheckerAgent):\n",
    "        self.translators = translators\n",
    "        self.editor = editor\n",
    "        self.quality_checker = quality_checker\n",
    "\n",
    "    def process_segments(self, segments: List[dict]) -> List[dict]:\n",
    "        # Translation\n",
    "        results = []\n",
    "        for i, seg in enumerate(segments):\n",
    "            translator = self.translators[i % len(self.translators)]\n",
    "            translated_text = translator.translate_text(seg[\"text\"])\n",
    "            results.append({\n",
    "                \"speaker_id\": seg[\"speaker_id\"],\n",
    "                \"start\": seg[\"start\"],\n",
    "                \"end\": seg[\"end\"],\n",
    "                \"translated_text\": translated_text\n",
    "            })\n",
    "\n",
    "        # Stylistic Editing\n",
    "        all_translations = [r[\"translated_text\"] for r in results]\n",
    "        improved = self.editor.improve_style(all_translations)\n",
    "        for i, r in enumerate(results):\n",
    "            r[\"translated_text\"] = improved[i]\n",
    "\n",
    "        # Quality Check\n",
    "        final_texts = [r[\"translated_text\"] for r in results]\n",
    "        if not self.quality_checker.check_quality(final_texts):\n",
    "            fixed = self.quality_checker.suggest_fixes(final_texts)\n",
    "            for i, r in enumerate(results):\n",
    "                r[\"translated_text\"] = fixed[i]\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "def extract_terminology_and_domain_knowledge(client: OpenAI, source_text: str, target_language: str = \"en\"):\n",
    "    \"\"\"\n",
    "    Extract domain-specific terms and glossary entries from a given source text.\n",
    "\n",
    "    Attempts to force the model to respond with a function call.\n",
    "    If not successful, attempts to parse JSON from the assistant's textual output.\n",
    "    \"\"\"\n",
    "    function_definition = {\n",
    "        \"name\": \"extract_domain_and_glossary\",\n",
    "        \"description\": \"Extract domain-specific terms and initial glossary terms from text, returning structured dictionaries.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"domain_knowledge\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"description\": \"Key-value pairs of domain-specific terms mapped to their explanations or translations\",\n",
    "                    \"additionalProperties\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"initial_glossary\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"description\": \"Key-value pairs of terms mapped to their target equivalents\",\n",
    "                    \"additionalProperties\": {\"type\": \"string\"}\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"domain_knowledge\", \"initial_glossary\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a terminology extraction assistant. Only respond by calling the function. Do not provide any other text.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "Analyze the following text and identify:\n",
    "1. Domain-specific terms (technical jargon, specialized components) relevant to the domain. For each domain-specific term, provide a short explanation or a translation into {target_language}.\n",
    "2. An initial glossary of key terms (proper nouns, repetitive keywords) and their target equivalents in {target_language}.\n",
    "\n",
    "Return your answer by calling the function `extract_domain_and_glossary` only, with a JSON structure:\n",
    "{{\n",
    "  \"domain_knowledge\": {{ \"term_in_source\": \"explanation_or_translation_in_{target_language}\" }},\n",
    "  \"initial_glossary\": {{ \"term_in_source\": \"equivalent_in_{target_language}\" }}\n",
    "}}\n",
    "\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": source_text}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "        functions=[function_definition],\n",
    "        function_call={\"name\": \"extract_domain_and_glossary\"},\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "    function_call_data = response.choices[0].message.function_call\n",
    "\n",
    "    if function_call_data is not None and function_call_data.arguments:\n",
    "        arguments_str = function_call_data.arguments\n",
    "        parsed = json.loads(arguments_str)\n",
    "    else:\n",
    "        # Fallback: Attempt to parse from assistant's textual output\n",
    "        assistant_content = response.choices[0].message.content\n",
    "        match = re.search(r'```json\\n(.*?)\\n```', assistant_content, re.DOTALL)\n",
    "        if match:\n",
    "            json_str = match.group(1)\n",
    "            parsed = json.loads(json_str)\n",
    "        else:\n",
    "            # If we cannot parse anything, return empty dicts\n",
    "            parsed = {\"domain_knowledge\": {}, \"initial_glossary\": {}}\n",
    "\n",
    "    extraction_result = ExtractionResult(**parsed)\n",
    "    return extraction_result.domain_knowledge, extraction_result.initial_glossary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "# from models import SegmentInput, TranslatedSegment, FinalOutput\n",
    "# from agents import (DomainExpertAgent, TerminologyAgent, TranslatorAgent, \n",
    "#                     StylisticEditorAgent, QualityCheckerAgent, GlobalCoordinatorAgent)\n",
    "# from functions import extract_terminology_and_domain_knowledge\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Initialize the OpenAI client\n",
    "    client = OpenAI(\n",
    "        base_url=\"http://localhost:1234/v1\",\n",
    "        api_key='lms'\n",
    "    )\n",
    "\n",
    "    # Example input\n",
    "    input_json = \"\"\"\n",
    "    [\n",
    "        {\"speaker_id\": \"S1\", \"start\":0.0, \"end\":2.5, \"text\":\"Bonjour, comment l'examen s'est derouler ?\"},\n",
    "        {\"speaker_id\": \"S2\", \"start\":2.5, \"end\":5.0, \"text\":\"l'examen etait un jeu d'enfant\"},\n",
    "        {\"speaker_id\": \"S1\", \"start\":5.0, \"end\":7.0, \"text\":\"super, content de l'entendre\"}\n",
    "    ]\n",
    "    \"\"\"\n",
    "\n",
    "    segments = [SegmentInput(**item) for item in json.loads(input_json)]\n",
    "\n",
    "    # Extract domain knowledge and initial glossary\n",
    "    target_language = \"en\"\n",
    "    domain_knowledge, initial_glossary = extract_terminology_and_domain_knowledge(client, \"Texte source ci-dessus\", target_language)\n",
    "\n",
    "    domain_agent = DomainExpertAgent(domain_knowledge=domain_knowledge)\n",
    "    terminology_agent = TerminologyAgent(initial_glossary=initial_glossary)\n",
    "\n",
    "    translator_1 = TranslatorAgent(target_lang=target_language, terminology_agent=terminology_agent, domain_agent=domain_agent, client=client)\n",
    "    translator_2 = TranslatorAgent(target_lang=target_language, terminology_agent=terminology_agent, domain_agent=domain_agent, client=client)\n",
    "\n",
    "    stylistic_editor = StylisticEditorAgent(client=client)\n",
    "    quality_checker = QualityCheckerAgent(client=client)\n",
    "\n",
    "    coordinator = GlobalCoordinatorAgent(translators=[translator_1, translator_2],\n",
    "                                         editor=stylistic_editor, \n",
    "                                         quality_checker=quality_checker)\n",
    "\n",
    "    # Process segments\n",
    "    final_results_raw = coordinator.process_segments([s.model_dump() for s in segments])\n",
    "    final_results = [TranslatedSegment(**r) for r in final_results_raw]\n",
    "\n",
    "    # Define function schema for the final output\n",
    "    function_definition_output = {\n",
    "        \"name\": \"generate_output\",\n",
    "        \"description\": \"Generate structured output with cultural references, wordplay, idiomatic expressions, acronyms, measurement units, and final translated segments.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"cultural_references\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"description\": \"List of detected cultural references.\"\n",
    "                },\n",
    "                \"wordplay\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"description\": \"List of instances of wordplay.\"\n",
    "                },\n",
    "                \"idiomatic_expressions\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"description\": \"List of idiomatic expressions.\"\n",
    "                },\n",
    "                \"acronyms\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"description\": \"List of acronyms.\"\n",
    "                },\n",
    "                \"measurement_units\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"description\": \"List of measurement units.\"\n",
    "                },\n",
    "                \"translated_segments\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"description\": \"The translated segments.\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"speaker_id\": {\"type\": \"string\"},\n",
    "                            \"start\": {\"type\": \"number\"},\n",
    "                            \"end\": {\"type\": \"number\"},\n",
    "                            \"translated_text\": {\"type\": \"string\"}\n",
    "                        },\n",
    "                        \"required\": [\"speaker_id\", \"start\", \"end\", \"translated_text\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"translated_segments\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    final_prompt = (\n",
    "        \"Analyze the following translated segments and extract:\\n\"\n",
    "        \"- Cultural references\\n\"\n",
    "        \"- Wordplay\\n\"\n",
    "        \"- Idiomatic expressions\\n\"\n",
    "        \"- Acronyms\\n\"\n",
    "        \"- Measurement units\\n\\n\"\n",
    "        \"Then return a JSON structure with these fields plus the translated segments.\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that returns data in a structured format.\"},\n",
    "        {\"role\": \"user\", \"content\": final_prompt},\n",
    "        {\"role\": \"user\", \"content\": json.dumps([r.model_dump() for r in final_results], ensure_ascii=False)}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "        functions=[function_definition_output],\n",
    "        function_call={\"name\": \"generate_output\"},\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "    # Attempt to retrieve function call arguments\n",
    "    func_call_data = response.choices[0].message.function_call\n",
    "    if func_call_data is not None and func_call_data.arguments:\n",
    "        structured_output_str = func_call_data.arguments\n",
    "    else:\n",
    "        # Fallback: Attempt to parse JSON from message content\n",
    "        assistant_content = response.choices[0].message.content\n",
    "        match = re.search(r'```json\\n(.*?)\\n```', assistant_content, re.DOTALL)\n",
    "        if match:\n",
    "            structured_output_str = match.group(1)\n",
    "        else:\n",
    "            # Ensure a dictionary structure to avoid TypeError\n",
    "            structured_output_str = json.dumps({\"translated_segments\": [r.model_dump() for r in final_results]})\n",
    "\n",
    "    # Load structured output as JSON\n",
    "    structured_output = json.loads(structured_output_str)\n",
    "\n",
    "    # Ensure structured_output is a dict (mapping)\n",
    "    # If it's not, wrap it or handle it. Typically, the prompt should produce a dict.\n",
    "    if not isinstance(structured_output, dict):\n",
    "        # If the model incorrectly returned a list, wrap it.\n",
    "        # For example, if structured_output is a list of segments:\n",
    "        structured_output = {\"translated_segments\": structured_output}\n",
    "\n",
    "    # Now parse into FinalOutput\n",
    "    parsed_output = FinalOutput(**structured_output)\n",
    "\n",
    "    # Print final output\n",
    "    print(json.dumps(parsed_output.model_dump(), indent=4, ensure_ascii=False))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"cultural_references\": [],\n",
      "    \"wordplay\": [],\n",
      "    \"idiomatic_expressions\": [],\n",
      "    \"acronyms\": [],\n",
      "    \"measurement_units\": [],\n",
      "    \"translated_segments\": [\n",
      "        {\n",
      "            \"speaker_id\": \"S1\",\n",
      "            \"start\": 0.0,\n",
      "            \"end\": 2.5,\n",
      "            \"translated_text\": \"Here's a revised version of the translated segment with improved style and fluency:\\n\\n\\\"Hello, how did your exam go?\\\"\\n\\nChanges made:\\n- Added \\\"your\\\" to make the sentence more polite and considerate of the person being addressed.\\n- Changed \\\"derouler\\\" to \\\"go\\\", which is a more natural and idiomatic way to express the idea of an exam passing or completing.\\n- Added \\\"your\\\" before \\\"exam\\\" to make the sentence more specific and considerate of the person being addressed.\\n\\nThe revised segment maintains the same meaning as the original, but with a more polished and natural-sounding tone.\"\n",
      "        },\n",
      "        {\n",
      "            \"speaker_id\": \"S2\",\n",
      "            \"start\": 2.5,\n",
      "            \"end\": 5.0,\n",
      "            \"translated_text\": \"Here are the improved versions of the translated segment:\\n\\n1. Original translation: \\\"The exam was a game of children.\\\"\\n   Improved version: \\\"The exam was a child's play.\\\"\\n\\n2. More natural and idiomatic way:\\n   Improved version: \\\"The exam was a game kids play.\\\"\\n\\nOr, for an even more idiomatic expression:\\n   Improved version: \\\"The exam was a game kids play.\\\"\\n\\nIn both cases, the idiomatic expressions convey the same meaning as \\\"l'examen était un jeu d'enfant\\\" but in a more natural and fluent way.\"\n",
      "        },\n",
      "        {\n",
      "            \"speaker_id\": \"S1\",\n",
      "            \"start\": 5.0,\n",
      "            \"end\": 7.0,\n",
      "            \"translated_text\": \"Here are a few options to improve the style and fluency of the translated segment:\\n\\n1. \\\"That's super, I get it.\\\" (as suggested)\\n2. \\\"Sounds great, I understand.\\\"\\n3. \\\"That's awesome, got it.\\\"\\n4. \\\"Love it, I'm on the same page.\\\"\\n5. \\\"Sounds good to me, I understand.\\\"\\n\\nThese options aim to maintain the original meaning while using more natural and conversational language in English.\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepDub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
