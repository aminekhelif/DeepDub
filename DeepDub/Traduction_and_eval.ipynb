{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai==0.28) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai==0.28) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.10 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai==0.28\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "input_json_file = \"input.json\"\n",
    "example_json_content = [\n",
    "    {\n",
    "        \"segment\": 633,\n",
    "        \"start\": 1613.107,\n",
    "        \"end\": 1623.093,\n",
    "        \"text\": \"We can't be at each other's throats, so what I'm willing to do is give you 15% off the top, and you provide security and distribution if needed.\",\n",
    "        \"audio_file\": \"SPEAKER_17/segment_633/audio.wav\"\n",
    "    },\n",
    "    {\n",
    "        \"segment\": 634,\n",
    "        \"start\": 1623.5,\n",
    "        \"end\": 1630.0,\n",
    "        \"text\": \"That sounds good to me, but is that for the overall production?\",\n",
    "        \"audio_file\": \"SPEAKER_17/segment_634/audio.wav\"\n",
    "    },\n",
    "       {\n",
    "        \"segment\": 635,\n",
    "        \"start\": 1630.1,\n",
    "        \"end\": 1637.5,\n",
    "        \"text\":\"It's raining cats and dogs\",\n",
    "        \"audio_file\": \"SPEAKER_17/segment_635/audio.wav\"\n",
    "    },\n",
    "      {\n",
    "        \"segment\": 636,\n",
    "        \"start\": 1637.5,\n",
    "        \"end\": 1640.0,\n",
    "        \"text\": \"Getting this deal done is a piece of cake\",\n",
    "        \"audio_file\": \"SPEAKER_17/segment_636/audio.wav\"\n",
    "    }\n",
    "\n",
    "    ]\n",
    "with open (input_json_file,\"w\") as f:\n",
    "    json.dump(example_json_content,f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original text:  Thank you.\n",
      "\n",
      "Original text:  Typical of Victor Von Doom to build a 30-foot statue of himself.\n",
      "\n",
      "Original text: Well, it's obviously aimed at first-time visitors to create feelings of smallness.\n",
      "\n",
      "Original text: Maddox-y.\n",
      "\n",
      "Original text: Good thing it ain't working.\n",
      "\n",
      "Original text: Reed, what are we doing here?\n",
      "\n",
      "Original text: This guy's fast food's stripping all science.\n",
      "\n",
      "Original text: This wasn't our first stop, in case you forgot.\n",
      "\n",
      "Original text: Besides, Victor's not that bad.\n",
      "\n",
      "Original text: He's just a little larger than life.\n",
      "\n",
      "Original text:  My research suggests that exposure to a high-energy cosmic storm, born on solar winds, might have triggered the evolution of early planetary life.\n",
      "\n",
      "Original text: In six weeks, another cloud with the same elemental profile will pass Earth's orbit.\n",
      "\n",
      "Original text: A study conducted in space could fundamentally advance our knowledge about the structure of the human genome, cure countless diseases, extend human life, give kids a chance to live longer, stronger, healthier.\n",
      "\n",
      "Original text: Turn it off.\n",
      "\n",
      "Original text:  Please.\n",
      "\n",
      "Original text: I don't think I've explained my proposal fully.\n",
      "\n",
      "Original text: No, I think you have.\n",
      "\n",
      "Original text: Same old Reed, always stretching, reaching for the stars with the weight of the world on his back.\n",
      "\n",
      "Original text: But dreams don't pay the bills, do they?\n",
      "\n",
      "Original text: You remember when we were in school, we talked about working together.\n",
      "\n",
      "Original text: Well, that's what I was about to explain.\n",
      "\n",
      "Original text: The storm is deadly, but the shields on your station's control room are designed to protect any occupants inside.\n",
      "\n",
      "Original text:  So it's not just my money you want.\n",
      "\n",
      "Original text: It's my toys.\n",
      "\n",
      "Original text: Tell me, if NASA doesn't trust you, then why should I?\n",
      "\n",
      "Original text: That's my job.\n",
      "\n",
      "Original text: To stay a step ahead.\n",
      "\n",
      "Original text: To know what other men don't.\n",
      "\n",
      "Original text: I can't take this.\n",
      "\n",
      "Original text: Ben, this is business.\n",
      "\n",
      "Original text: Just work.\n",
      "\n",
      "Original text: He's right, Ben.\n",
      "\n",
      "Original text: It is just business.\n",
      "\n",
      "Original text:  I think you both know my director of genetic research, Susan Storm.\n",
      "\n",
      "Original text: One more thing he's got.\n",
      "\n",
      "Original text: Hey, Susie.\n",
      "\n",
      "Original text: Hey.\n",
      "\n",
      "Original text: Oh, it's so nice to see you.\n",
      "\n",
      "Original text: How's Debbie?\n",
      "\n",
      "Original text: Great.\n",
      "\n",
      "Original text: Great.\n",
      "\n",
      "Original text: How have you been?\n",
      "\n",
      "Original text: Never better.\n",
      "\n",
      "Original text: This isn't going to be a problem, is it?\n",
      "\n",
      "Original text: Oh, not at all.\n",
      "\n",
      "Original text: Good.\n",
      "\n",
      "Original text:  Then you were just in time to hear the great Reed Richards ask me for help.\n",
      "\n",
      "Original text: You know, you made a lot of folks at MIT feel like a junior high science fair, so you'll excuse me if I say for the moment.\n",
      "\n",
      "Original text: You back this mission, and I'll sign over a fair percentage of any applications.\n",
      "\n",
      "Original text: Number 75.\n",
      "\n",
      "Original text: And its applications and patents.\n",
      "\n",
      "Original text: What about his firstborn?\n",
      "\n",
      "Original text: Ben.\n",
      "\n",
      "Original text: Come on.\n",
      "\n",
      "Original text:  25% of a billion is enough to keep the lights on for a while, isn't it?\n",
      "\n",
      "Original text: Maybe even pay off your fourth mortgage on the Baxter building.\n",
      "\n",
      "Original text: Deal?\n",
      "\n",
      "Original text: Well then, to our future.\n",
      "\n",
      "Original text: Together.\n",
      "\n",
      "Original text: It's funny how things turn out, isn't it?\n",
      "\n",
      "Original text:  Hilarious.\n",
      "\n",
      "Original text: He knew about NASA.\n",
      "\n",
      "Original text: Maybe he made the call to shut us down.\n",
      "\n",
      "Original text: Ben, think about all the people we can help if this works.\n",
      "\n",
      "Original text: Huh?\n",
      "\n",
      "Original text: Look, we got what we wanted.\n",
      "\n",
      "Original text: That's enough.\n",
      "\n",
      "Original text: A few days in space.\n",
      "\n",
      "Original text: It'll be great.\n",
      "\n",
      "Original text: What's the worst that can happen?\n",
      "\n",
      "Original text: If Reed's right, this little trip could double our stock offerings.\n",
      "\n",
      "Original text: And if he's not?\n",
      "\n",
      "Original text: Reed's always right.\n",
      "\n",
      "Original text:  Good thing he doesn't always know what he's got.\n",
      "\n",
      "Original text: Reed, you should know those solar winds have been picking up speed.\n",
      "\n",
      "Original text: I factored them into my coordinates.\n",
      "\n",
      "Original text: Right.\n",
      "\n",
      "Original text: Of course you did.\n",
      "\n",
      "Original text: In theory.\n",
      "\n",
      "Original text: It's a little different when you're out there.\n",
      "\n",
      "Original text: I can assure you I factored... When are we leaving?\n",
      "\n",
      "Original text: I'll be scheduling the launch, so you can call me in the morning for resources and crew.\n",
      "\n",
      "Original text:  I think I remember the number.\n",
      "\n",
      "Original text: It's been changed.\n",
      "\n",
      "Original text: As far as crew, I was hoping Ben could pilot the mission.\n",
      "\n",
      "Original text: We already have a pilot on our payroll, but you're welcome to ride shotgun.\n",
      "\n",
      "Original text: Remember my brother Johnny?\n",
      "\n",
      "Original text:  Can't do it.\n",
      "\n",
      "Original text: Cannot do it.\n",
      "\n",
      "Original text: External SRBs, orbital system engines.\n",
      "\n",
      "Original text: It's just like the shuttle you flew.\n",
      "\n",
      "Original text: No.\n",
      "\n",
      "Original text: I cannot take orders from the underwear model.\n",
      "\n",
      "Original text: Oh, come on now.\n",
      "\n",
      "Original text: That wingnut washed out of NASA for sneaking two Victoria's Secret wannabes into a flight simulator.\n",
      "\n",
      "Original text: Youthful high spirits.\n",
      "\n",
      "Original text: They crashed it into a wall.\n",
      "\n",
      "Original text: A flight simulator.\n",
      "\n",
      "Original text:  When have I ever asked you to do something you absolutely said you could not do?\n",
      "\n",
      "Original text: Five times.\n",
      "\n",
      "Original text: I had it at four.\n",
      "\n",
      "Original text: Well, this makes five.\n",
      "\n",
      "Original text: I miss you already, Debs.\n",
      "\n",
      "Original text: Captain on the bridge!\n",
      "\n",
      "Original text:  Digital camera, $254.\n",
      "\n",
      "Original text: Memory stick, $59.\n",
      "\n",
      "Original text: The look on your hard-ass former CO's face when he finds out he's your junior officer.\n",
      "\n",
      "Original text: Priceless.\n",
      "\n",
      "Original text: Thank you, sweetie.\n",
      "\n",
      "Original text: I can handle the ship.\n",
      "\n",
      "Original text: I can even handle Mr. Blonde Ambition.\n",
      "\n",
      "Original text: I don't know whether I should be flying or doing Swan Lake in these suits.\n",
      "\n",
      "Original text: I mean, who the hell came up with these?\n",
      "\n",
      "Original text: Victor did.\n",
      "\n",
      "Original text: The synthetics act as a second skin.\n",
      "\n",
      "Original text:  adapting to your body's individual needs.\n",
      "\n",
      "Original text: See, now that needs.\n",
      "\n",
      "Original text: It keeps the hot stuff hot, and it keeps the cool stuff cool.\n",
      "\n",
      "Original text: Wow.\n",
      "\n",
      "Original text: Fantastic.\n",
      "\n",
      "Original text: Material made from self-regulating, unstable molecules.\n",
      "\n",
      "Original text: I've been working on a formula for this.\n",
      "\n",
      "Original text: Great minds think alike.\n",
      "\n",
      "Original text: Here you go, Ben.\n",
      "\n",
      "Original text: Thanks, sweetie.\n",
      "\n",
      "Original text: Reed?\n",
      "\n",
      "Original text:  ETA until cosmic event.\n",
      "\n",
      "Original text: Nine hours.\n",
      "\n",
      "Original text: If you're good, maybe next time Daddy will let you drive.\n",
      "\n",
      "Original text: Keep talking and there won't be a next time.\n",
      "\n",
      "Original text: Long way from the projection booth at the Hayden Planetarium, isn't it?\n",
      "\n",
      "Original text:  Yes.\n",
      "\n",
      "Original text: Yes, it is.\n",
      "\n",
      "Original text: We can monitor the cloud's approach and observe the test from here.\n",
      "\n",
      "Original text: Is it safe?\n",
      "\n",
      "Original text: The shields on the station should protect us.\n",
      "\n",
      "Original text: Should?\n",
      "\n",
      "Original text: What's the matter, Ben?\n",
      "\n",
      "Original text: Getting paranoid in your old age?\n",
      "\n",
      "Original text: Let's start loading those samples.\n",
      "\n",
      "Original text: Get your suit ready, Ben.\n",
      "\n",
      "Original text: So I see you're still doing all the heavy lifting.\n",
      "\n",
      "Original text: Maybe you should have stayed in the lab.\n",
      "\n",
      "Original text:  Field work never suited you.\n",
      "\n",
      "Original text: He does the talking.\n",
      "\n",
      "Original text: I do the walking.\n",
      "\n",
      "Original text: Got it?\n",
      "\n",
      "Original text: So take a walk, Ben.\n",
      "\n",
      "Original text: Actually, if you'll all excuse me, I need to borrow Susan for a moment.\n",
      "\n",
      "Original text: Sure.\n",
      "\n",
      "Translation complete! Results saved to: example_translated.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "\n",
    "# ====== CONFIGURATION ======\n",
    "openai.api_key = \"sk-YourAPIKey\"  # Set your OpenAI API key here\n",
    "model_name = \"gpt-3.5-turbo\"            # Model to use for translation\n",
    "target_language = \"French\"               # Change to your desired target language\n",
    "input_file_path = \"diar_simple.json\"         # Input JSON file path\n",
    "output_file_path = \"example_translated.json\"  # Output JSON file path\n",
    "# ==========================\n",
    "\n",
    "def translate_text(text, target_language):\n",
    "    \"\"\"\n",
    "    Translates the given text into the target_language using OpenAI's ChatCompletion.\n",
    "    The system instruction includes a directive for detecting and preserving nuances\n",
    "    (idiomatic expressions, cultural references, etc.).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # We use ChatCompletion with a system message to instruct the model\n",
    "        # on how we want the translation to be performed.\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You are a highly skilled translator. \"\n",
    "                        \"Your task is to detect the source language automatically and translate it into \"\n",
    "                        f\"{target_language} while preserving context, nuances, cultural references, wordplay, \"\n",
    "                        \"idiomatic expressions, acronyms, measurement units, and slang terms. \"\n",
    "                        \"If there's wordplay or idiomatic expressions that need adaptation, do so while keeping \"\n",
    "                        \"the same intent and style.\"\n",
    "                    )\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": text\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.2  # Lower temperature for more consistent translations\n",
    "        )\n",
    "\n",
    "        # Extract the translated text from the response\n",
    "        translated_text = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        return translated_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during translation: {e}\")\n",
    "        return text  # Fallback to original text if there's an error\n",
    "\n",
    "def main():\n",
    "    # 1. Read the input JSON file\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 2. Iterate over each item in the JSON list and translate the \"text\" field\n",
    "    for item in data:\n",
    "        original_text = item.get(\"text\", \"\")\n",
    "        \n",
    "        # Provide an option for manual translation\n",
    "        print(f\"\\nOriginal text: {original_text}\")\n",
    "        #user_input = input(\n",
    "            #\"Press ENTER to auto-translate OR type/paste your manual translation here:\\n> \"\n",
    "        #).strip()\n",
    "        \n",
    "        #if user_input:\n",
    "            # If user provided a manual translation, use it\n",
    "            #translated_text = user_input\n",
    "        #else:\n",
    "            # Otherwise, auto-translate using OpenAI\n",
    "        translated_text = translate_text(original_text, target_language)\n",
    "        \n",
    "        # Store or update the item with the translated text\n",
    "        item[\"translated_text\"] = translated_text\n",
    "    \n",
    "    # 3. Save the updated data to a new JSON file\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nTranslation complete! Results saved to: {output_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation ( d-Bleu, bert-score, comet-qe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacrebleu in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: portalocker in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sacrebleu) (3.1.1)\n",
      "Requirement already satisfied: regex in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sacrebleu) (2024.5.15)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sacrebleu) (1.26.3)\n",
      "Requirement already satisfied: colorama in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.10 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round-trip translation (for evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# =========== CONFIGURATION ===========\n",
    "openai.api_key = \"sk-YourAPIKey\"  # Set your OpenAI API key here\n",
    "model_name = \"gpt-3.5-turbo\"            # Modèle utilisé pour la traduction\n",
    "input_file = \"eval_translated.json\"  # Fichier qui contient la traduction\n",
    "output_file = \"backtranslated_3.5.json\"\n",
    "# =====================================\n",
    "\n",
    "def back_translate(text, source_lang=\"French\", target_lang=\"English\"):\n",
    "    \"\"\"\n",
    "    Effectue la back-translation du texte (source_lang -> target_lang) via OpenAI.\n",
    "    Ici, on suppose que la traduction existante est en 'French' et que l'original\n",
    "    était en 'English'. Ajustez si nécessaire.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        f\"Tu es un traducteur expérimenté. \"\n",
    "                        f\"Traduis le texte ci-dessous du {source_lang} vers le {target_lang} \"\n",
    "                        f\"en préservant le sens et les nuances.\"\n",
    "                    )\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": text\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.2\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur pendant la back-translation: {e}\")\n",
    "        return text  # Fallback: renvoie le texte d'entrée s'il y a une erreur\n",
    "\n",
    "def main():\n",
    "    # 1. Lire le fichier JSON contenant la traduction\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Préparer des listes pour le calcul du score BLEU (corpus-level)\n",
    "    original_texts = []\n",
    "    back_translated_texts = []\n",
    "    \n",
    "    # 2. Faire la back-translation pour chaque item\n",
    "    for item in data:\n",
    "        original_text = item.get(\"text\", \"\")\n",
    "        translated_text = item.get(\"translated_text\", \"\")\n",
    "\n",
    "        # Back-translation du 'translated_text' vers la langue source (ici, English)\n",
    "        back_translated = back_translate(translated_text, source_lang=\"French\", target_lang=\"English\")\n",
    "        \n",
    "        # On stocke la back-translation dans l'item\n",
    "        item[\"back_translated_text\"] = back_translated\n",
    "        \n",
    "        # On accumule pour calculer un BLEU \"corpus\" à la fin\n",
    "        original_texts.append(original_text)\n",
    "        back_translated_texts.append(back_translated)\n",
    "    \n",
    "    # 3. Calculer le score BLEU global (corpus-level)\n",
    "    #    Note: sacrebleu.corpus_bleu prend en entrée:\n",
    "    #      - hypotheses: liste des textes hypothèses (ici, back_translated_texts)\n",
    "    #      - references: liste de listes (ou single reference), ex. [[ref1, ref2, ...], [ref1, ref2, ...], ...]\n",
    "    #    Donc on encapsule original_texts dans une liste\n",
    "    bleu = sacrebleu.corpus_bleu(back_translated_texts, [original_texts])\n",
    "    bleu_score = bleu.score\n",
    "    \n",
    "    # 4. Sauvegarder dans un nouveau fichier JSON\n",
    "    #    On peut ajouter un champ \"bleu_score\" global à la racine ou l'afficher.\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Back-translation terminée. Fichier généré : {output_file}\")\n",
    "    print(f\"Score BLEU (corpus) = {bleu_score:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"backtranslated_3.5.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back-translation terminée. Fichier généré : backtranslated_3.5.json\n",
      "Score BLEU (corpus) = 48.07\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        original_texts = []\n",
    "        back_translated_texts = []\n",
    "\n",
    "        for item in data:\n",
    "\n",
    "            original_text = item.get(\"text\", \"\")\n",
    "            translated_text = item.get(\"translated_text\", \"\")\n",
    "            back_translated = item.get(\"back_translated_text\", \"\")\n",
    "            original_texts.append(original_text)\n",
    "            back_translated_texts.append(back_translated)\n",
    "        \n",
    "        bleu = sacrebleu.corpus_bleu(back_translated_texts, [original_texts])\n",
    "        bleu_score = bleu.score\n",
    "        print(f\"Back-translation terminée. Fichier généré : {output_file}\")\n",
    "        print(f\"Score BLEU (corpus) = {bleu_score:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "un score BLEU autour de 40 pour de la back-translation indique généralement une bonne préservation du sens et des structures principales.\n",
    "\n",
    "Si vous aviez un score BLEU très faible (ex. < 20), ça pourrait indiquer que la traduction ou la back-traduction s’est grandement éloignée de l’original.\n",
    "\n",
    "À l’inverse, un score élevé (ex. 70+) signifierait que la back-traduction est extrêmement proche de la phrase d’origine sur le plan lexical. Cela peut être souhaitable, ou au contraire indiquer une traduction trop littérale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score) (2.2.2)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score) (2.2.2)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score) (4.47.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score) (1.26.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score) (4.66.1)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score) (3.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.26.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->bert-score) (4.31.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->bert-score) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->bert-score) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->bert-score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->bert-score) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->bert-score) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->bert-score) (2023.11.17)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.10 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bert-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de segments évalués : 150\n",
      "Score BERTScore (moyenne) :\n",
      "  - Precision: 0.9609\n",
      "  - Recall:    0.9659\n",
      "  - F1:        0.9633\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from bert_score import score\n",
    "\n",
    "# On suppose que le fichier contenant l'original, la traduction et la back-traduction s'appelle:\n",
    "input_file = \"backtranslated_3.5.json\"\n",
    "\n",
    "def main():\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    original_texts = []\n",
    "    backtranslated_texts = []\n",
    "\n",
    "    for item in data:\n",
    "        original = item.get(\"text\", \"\")\n",
    "        backtrans = item.get(\"back_translated_text\", \"\")\n",
    "\n",
    "        # On stocke la version anglaise originale et la version back-traduite\n",
    "        original_texts.append(original)\n",
    "        backtranslated_texts.append(backtrans)\n",
    "\n",
    "    # BERTScore nécessite que la référence et l'hypothèse soient dans la même langue (anglais, ici).\n",
    "    # Par défaut, lang=\"en\" => BERTScore utilise un modèle anglais\n",
    "    P, R, F1 = score(backtranslated_texts, original_texts, lang=\"en\")\n",
    "\n",
    "    print(f\"Nombre de segments évalués : {len(original_texts)}\")\n",
    "    print(f\"Score BERTScore (moyenne) :\")\n",
    "    print(f\"  - Precision: {P.mean():.4f}\")\n",
    "    print(f\"  - Recall:    {R.mean():.4f}\")\n",
    "    print(f\"  - F1:        {F1.mean():.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- F1 est souvent utilisé comme score global (entre 0 et 1). Plus c’est proche de 1, plus les phrases sont considérées sémantiquement similaires.\n",
    "- on peut aussi consulter la Precision et le Recall, pour voir comment les tokens s’alignent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
