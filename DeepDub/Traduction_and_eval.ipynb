{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai==0.28) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai==0.28) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.10 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai==0.28\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "input_json_file = \"input.json\"\n",
    "example_json_content = [\n",
    "    {\n",
    "        \"segment\": 633,\n",
    "        \"start\": 1613.107,\n",
    "        \"end\": 1623.093,\n",
    "        \"text\": \"We can't be at each other's throats, so what I'm willing to do is give you 15% off the top, and you provide security and distribution if needed.\",\n",
    "        \"audio_file\": \"SPEAKER_17/segment_633/audio.wav\"\n",
    "    },\n",
    "    {\n",
    "        \"segment\": 634,\n",
    "        \"start\": 1623.5,\n",
    "        \"end\": 1630.0,\n",
    "        \"text\": \"That sounds good to me, but is that for the overall production?\",\n",
    "        \"audio_file\": \"SPEAKER_17/segment_634/audio.wav\"\n",
    "    },\n",
    "       {\n",
    "        \"segment\": 635,\n",
    "        \"start\": 1630.1,\n",
    "        \"end\": 1637.5,\n",
    "        \"text\":\"It's raining cats and dogs\",\n",
    "        \"audio_file\": \"SPEAKER_17/segment_635/audio.wav\"\n",
    "    },\n",
    "      {\n",
    "        \"segment\": 636,\n",
    "        \"start\": 1637.5,\n",
    "        \"end\": 1640.0,\n",
    "        \"text\": \"Getting this deal done is a piece of cake\",\n",
    "        \"audio_file\": \"SPEAKER_17/segment_636/audio.wav\"\n",
    "    }\n",
    "\n",
    "    ]\n",
    "with open (input_json_file,\"w\") as f:\n",
    "    json.dump(example_json_content,f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import getpass\n",
    "from typing import List, Optional\n",
    "\n",
    "import openai\n",
    "from pydantic import BaseModel, ValidationError, RootModel\n",
    "\n",
    "# ========= CONFIGURATION ==========\n",
    "\n",
    "openai_api_key = getpass.getpass(\"Veuillez saisir votre clé OpenAI : \")\n",
    "openai.api_key = openai_api_key  # Clé OpenAI\n",
    "\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "target_language = \"French\"\n",
    "input_file_path = \"input_text.json\"\n",
    "output_file_path = \"output_text.json\"\n",
    "CHUNK_SIZE = 30\n",
    "\n",
    "# ========= PYDANTIC MODELS ==========\n",
    "\n",
    "class TranslatedSegment(BaseModel):\n",
    "    \n",
    "    start: Optional[float]\n",
    "    end: Optional[float]\n",
    "    text: str\n",
    "    speaker: Optional[str]\n",
    "    translated_text: str\n",
    "\n",
    "class TranslatedSegmentList(RootModel[List[TranslatedSegment]]):\n",
    "    \"\"\"A root model representing a list of TranslatedSegment objects.\"\"\"\n",
    "\n",
    "# ========= FONCTIONS ==========\n",
    "\n",
    "def build_user_message_for_chunk(chunk: List[dict]) -> str:\n",
    "    prompt_intro = (\n",
    "        \"Below is a list of segments in JSON format. \"\n",
    "        \"For each segment:\\n\"\n",
    "        \"- Do NOT modify the 'text' field (it must remain in the source language).\\n\"\n",
    "        f\"- Create or fill 'translated_text' with the translation into {target_language}.\\n\\n\"\n",
    "        \"Return a valid JSON array of objects, where each object preserves the original fields \"\n",
    "        \"(segment, start, end, text) and includes a new field 'translated_text'.\\n\"\n",
    "        \"Example:\\n\"\n",
    "        \"[\\n\"\n",
    "        \"  {\\n\"\n",
    "          \n",
    "        \"    \\\"start\\\": 0.0,\\n\"\n",
    "        \"    \\\"end\\\": 5.0,\\n\"\n",
    "        \"    \\\"text\\\": \\\"This is the original text.\\\",\\n\"\n",
    "        \"    \\\"speaker\\\": \\\"SPEAKER_1\\\",\\n\"\n",
    "        \"    \\\"translated_text\\\": \\\"Voici le texte traduit.\\\" \\n\"\n",
    "        \"  }\\n\"\n",
    "        \"]\\n\\n\"\n",
    "        \"Important:\\n\"\n",
    "        \"- Translate from detected source language to the target language.\\n\"\n",
    "        \"- Preserve nuances, cultural references, wordplay, idiomatic expressions, etc.\\n\"\n",
    "        \"- Any symbols, measurement units, or numbers must be written out in words.\\n\"\n",
    "        \n",
    "    )\n",
    "\n",
    "    chunk_json = json.dumps(chunk, ensure_ascii=False, indent=2)\n",
    "    user_message = f\"{prompt_intro}\\n\\nHere is the chunk to translate:\\n{chunk_json}\\n\\n\"\n",
    "    return user_message\n",
    "\n",
    "def translate_chunk(chunk: List[dict]) -> List[TranslatedSegment]:\n",
    "    user_message = build_user_message_for_chunk(chunk)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a highly skilled translator. \"\n",
    "        \"First, read the entire set of segments to fully grasp overall context. \"\n",
    "        \"Then, translate each segment's 'text' field into the target language while preserving context, \"\n",
    "        \"nuances, cultural references, wordplay, idiomatic expressions, acronyms, measurement units, slang, \"\n",
    "        \"and so on. If there's any wordplay or idiomatic expression that needs adaptation, keep the same intent and style. \"\n",
    "        \"make sure to not translate the names of people, companies, or brands. \"\n",
    "        \"All symbols, numbers, or measurement units must be written out in full words in the target language. (e.g., 5 kilometers -> cinq kilomètres, % -> pour cent, $ -> dollars, etc.) \"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            temperature=0.2\n",
    "        )\n",
    "        llm_output = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "        # On essaye de parser la réponse comme JSON\n",
    "        data = json.loads(llm_output)\n",
    "        # On le valide via Pydantic RootModel\n",
    "        validated = TranslatedSegmentList.parse_obj(data)\n",
    "        return validated.root\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        print(\"Erreur de parsing ou de validation Pydantic :\", e)\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur d'appel OpenAI pour le chunk : {e}\")\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    \n",
    "    with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(\"Le fichier d'entrée doit être une liste JSON de segments.\")\n",
    "\n",
    "    all_translated_segments = []\n",
    "\n",
    "    for i in range(0, len(data), CHUNK_SIZE):\n",
    "        chunk = data[i : i + CHUNK_SIZE]\n",
    "        print(f\"\\n--- Traitement du chunk n°{i//CHUNK_SIZE + 1} contenant {len(chunk)} segments ---\")\n",
    "\n",
    "        translated_items = translate_chunk(chunk)\n",
    "        # Ajout au tableau global\n",
    "        all_translated_segments.extend([item.dict() for item in translated_items])\n",
    "\n",
    "    # Sauvegarde\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_translated_segments, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\nTraduction terminée ! Résultats enregistrés dans : {output_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation ( d-Bleu, bert-score, comet-qe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacrebleu in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: portalocker in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sacrebleu) (3.1.1)\n",
      "Requirement already satisfied: regex in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sacrebleu) (2024.5.15)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sacrebleu) (1.26.3)\n",
      "Requirement already satisfied: colorama in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.10 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round-trip translation (for evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# =========== CONFIGURATION ===========\n",
    "openai.api_key = \"sk-YourAPIKey\"  # Set your OpenAI API key here\n",
    "model_name = \"gpt-3.5-turbo\"            # Modèle utilisé pour la traduction\n",
    "input_file = \"eval_translated.json\"  # Fichier qui contient la traduction\n",
    "output_file = \"backtranslated_3.5.json\"\n",
    "# =====================================\n",
    "\n",
    "def back_translate(text, source_lang=\"French\", target_lang=\"English\"):\n",
    "    \"\"\"\n",
    "    Effectue la back-translation du texte (source_lang -> target_lang) via OpenAI.\n",
    "    Ici, on suppose que la traduction existante est en 'French' et que l'original\n",
    "    était en 'English'. Ajustez si nécessaire.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        f\"Tu es un traducteur expérimenté. \"\n",
    "                        f\"Traduis le texte ci-dessous du {source_lang} vers le {target_lang} \"\n",
    "                        f\"en préservant le sens et les nuances.\"\n",
    "                    )\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": text\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.2\n",
    "        )\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur pendant la back-translation: {e}\")\n",
    "        return text  # Fallback: renvoie le texte d'entrée s'il y a une erreur\n",
    "\n",
    "def main():\n",
    "    # 1. Lire le fichier JSON contenant la traduction\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Préparer des listes pour le calcul du score BLEU (corpus-level)\n",
    "    original_texts = []\n",
    "    back_translated_texts = []\n",
    "    \n",
    "    # 2. Faire la back-translation pour chaque item\n",
    "    for item in data:\n",
    "        original_text = item.get(\"text\", \"\")\n",
    "        translated_text = item.get(\"translated_text\", \"\")\n",
    "\n",
    "        # Back-translation du 'translated_text' vers la langue source (ici, English)\n",
    "        back_translated = back_translate(translated_text, source_lang=\"French\", target_lang=\"English\")\n",
    "        \n",
    "        # On stocke la back-translation dans l'item\n",
    "        item[\"back_translated_text\"] = back_translated\n",
    "        \n",
    "        # On accumule pour calculer un BLEU \"corpus\" à la fin\n",
    "        original_texts.append(original_text)\n",
    "        back_translated_texts.append(back_translated)\n",
    "    \n",
    "    # 3. Calculer le score BLEU global (corpus-level)\n",
    "    #    Note: sacrebleu.corpus_bleu prend en entrée:\n",
    "    #      - hypotheses: liste des textes hypothèses (ici, back_translated_texts)\n",
    "    #      - references: liste de listes (ou single reference), ex. [[ref1, ref2, ...], [ref1, ref2, ...], ...]\n",
    "    #    Donc on encapsule original_texts dans une liste\n",
    "    bleu = sacrebleu.corpus_bleu(back_translated_texts, [original_texts])\n",
    "    bleu_score = bleu.score\n",
    "    \n",
    "    # 4. Sauvegarder dans un nouveau fichier JSON\n",
    "    #    On peut ajouter un champ \"bleu_score\" global à la racine ou l'afficher.\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Back-translation terminée. Fichier généré : {output_file}\")\n",
    "    print(f\"Score BLEU (corpus) = {bleu_score:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"backtranslated_3.5.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back-translation terminée. Fichier généré : backtranslated_3.5.json\n",
      "Score BLEU (corpus) = 48.07\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        original_texts = []\n",
    "        back_translated_texts = []\n",
    "\n",
    "        for item in data:\n",
    "\n",
    "            original_text = item.get(\"text\", \"\")\n",
    "            translated_text = item.get(\"translated_text\", \"\")\n",
    "            back_translated = item.get(\"back_translated_text\", \"\")\n",
    "            original_texts.append(original_text)\n",
    "            back_translated_texts.append(back_translated)\n",
    "        \n",
    "        bleu = sacrebleu.corpus_bleu(back_translated_texts, [original_texts])\n",
    "        bleu_score = bleu.score\n",
    "        print(f\"Back-translation terminée. Fichier généré : {output_file}\")\n",
    "        print(f\"Score BLEU (corpus) = {bleu_score:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "un score BLEU autour de 40 pour de la back-translation indique généralement une bonne préservation du sens et des structures principales.\n",
    "\n",
    "Si vous aviez un score BLEU très faible (ex. < 20), ça pourrait indiquer que la traduction ou la back-traduction s’est grandement éloignée de l’original.\n",
    "\n",
    "À l’inverse, un score élevé (ex. 70+) signifierait que la back-traduction est extrêmement proche de la phrase d’origine sur le plan lexical. Cela peut être souhaitable, ou au contraire indiquer une traduction trop littérale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score) (2.2.2)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score) (2.2.2)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score) (4.47.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score) (1.26.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score) (4.66.1)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score) (3.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bert-score) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.26.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->bert-score) (4.31.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->bert-score) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->bert-score) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->bert-score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->bert-score) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->bert-score) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->bert-score) (2023.11.17)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.10 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bert-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de segments évalués : 150\n",
      "Score BERTScore (moyenne) :\n",
      "  - Precision: 0.9609\n",
      "  - Recall:    0.9659\n",
      "  - F1:        0.9633\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from bert_score import score\n",
    "\n",
    "# On suppose que le fichier contenant l'original, la traduction et la back-traduction s'appelle:\n",
    "input_file = \"backtranslated_3.5.json\"\n",
    "\n",
    "def main():\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    original_texts = []\n",
    "    backtranslated_texts = []\n",
    "\n",
    "    for item in data:\n",
    "        original = item.get(\"text\", \"\")\n",
    "        backtrans = item.get(\"back_translated_text\", \"\")\n",
    "\n",
    "        # On stocke la version anglaise originale et la version back-traduite\n",
    "        original_texts.append(original)\n",
    "        backtranslated_texts.append(backtrans)\n",
    "\n",
    "    # BERTScore nécessite que la référence et l'hypothèse soient dans la même langue (anglais, ici).\n",
    "    # Par défaut, lang=\"en\" => BERTScore utilise un modèle anglais\n",
    "    P, R, F1 = score(backtranslated_texts, original_texts, lang=\"en\")\n",
    "\n",
    "    print(f\"Nombre de segments évalués : {len(original_texts)}\")\n",
    "    print(f\"Score BERTScore (moyenne) :\")\n",
    "    print(f\"  - Precision: {P.mean():.4f}\")\n",
    "    print(f\"  - Recall:    {R.mean():.4f}\")\n",
    "    print(f\"  - F1:        {F1.mean():.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- F1 est souvent utilisé comme score global (entre 0 et 1). Plus c’est proche de 1, plus les phrases sont considérées sémantiquement similaires.\n",
    "- on peut aussi consulter la Precision et le Recall, pour voir comment les tokens s’alignent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
